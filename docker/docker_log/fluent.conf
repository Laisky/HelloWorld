# =================================================
# Fluentd configuration for SIT
# =================================================

<source>
  @type forward
  port 24225
  bind 0.0.0.0
</source>

<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24326
</source>

# ---------------------------------------------------------------
# kafka
# ---------------------------------------------------------------
<source>
  @type kafka_group
  brokers xxx
  consumer_group paas_log_platform_sit
  topics logaiSit
  format text
  add_prefix kafka.spark.sit
  start_from_beginning false
  max_bytes 10485760
  max_wait_time 3
</source>

<match kafka.spark.sit.**>
  @type rewrite_tag_filter
  <rule>
    key message
    pattern .*
    tag spark.sit
  </rule>
</match>

# ---------------------------------------------------------------
# dispacher for all
# ---------------------------------------------------------------
<match spring.sit>
  @type rewrite_tag_filter
  <rule>  # cp log
    key log
    pattern ms:cp
    tag cp.sit
  </rule>
  <rule>  # baidu bot
    key log
    pattern ms_\w+\ {0,}\|
    tag bot.sit
  </rule>
  <rule>  # spring ordinary log
    key log
    pattern .*
    tag app.spring.sit  # avoid conflict
  </rule>
</match>

# ---------------------------------------------------------------
# spark
# ---------------------------------------------------------------
<match spark.test>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name es-stats
    type_name sit-spark
    num_threads 1
    include_timestamp true
    # buffer
    # buffer_type file
    # flush_interval 5
    # buffer_path /data/log/td-agent/buffer/sit-log-spark
  </store>
  <store>
    @type stdout
  </store>
</match>

<filter spark.sit>
  @type ignore
  regexp1 message /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2},\d{3} +\[/
</filter>

<filter spark.sit>
  @type concat
  key message # for kafka
  # key log # for docker
  stream_identity_key container_id
  # 1. spark log from kafka
  #     2018/03/06 15:19:23.619 INFO 6356e435e4894a22a41c80e6ade35526 com.pateo.qingcloud.ai.sparkstreaming.db.AiDbService: Enter getFuseDataType  function!
  multiline_start_regexp /^\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}.\d{3} \w+ /
  # 2. spark log from file
  #     18/01/26 07:24:16 INFO Executor: Finished task 9.0 in stage 28
  # multiline_start_regexp /^\d{2}/\d{2}/\d{2} +\d{2}:\d{2}:\d{2} +[^ ]+ +[^ ]+/
</filter>

<filter spark.sit>
  @type parser
  key_name message # for kafka
  # key_name log # for docker
  reserve_data false
  <parse>
    @type multiline
    # 1. spark log from kafka
    #     2018/03/06 15:19:23.619 INFO 6356e435e4894a22a41c80e6ade35526 com.pateo.qingcloud.ai.sparkstreaming.db.AiDbService: Enter getFuseDataType  function!
    format_firstline /^\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}.\d{3} \w+ /
    format1 /^(?<time>.{23}) {0,}(?<level>[^ ]+) +(?<uuid>[^ ]+) +(?<app_info>[^:]+) {0,}: {0,}(?<message>.*)/
    # 2. sprak log from file
    # format_firstline /^\d{2}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} [^ ]+ [^ ]+/
    # format1 /(?<time>.{17}) +(?<level>[^ ]+) +(?<app_info>[^ ]+) {0,}: ?(?<message>.*)/
    time_key time
    keep_time_key false
    time_format "%Y/%m/%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

# <match spark.sit>
#   @type stdout
# </match>

<match spark.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-spark-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
    # buffer
    # buffer_type file
    # flush_interval 3s
    # buffer_path /data/log/td-agent/buffer/sit-log-spark-app
  </store>
  <store>
    @type flowcounter
    count_keys message
    unit hour
    tag fluentd.stats
  </store>
</match>

# ---------------------------------------------------------------
# cp
# ---------------------------------------------------------------
<filter cp.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    # 2018-02-01 16:15:43.518 - ms:cp|type:platform|uuid:4f99962d-c272-43bb-85d9-20ab030180b7|dateTime:2018-02-01 16:15:43.518|customerSid:27|customerCode:DT00000000|customerName:默认
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}.\d{3} - ms:cp|/
    format1 /^(?<time>.{23}) - (?<message>ms:cp.*)/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<filter cp.sit>
  @type record_transformer
  <record>
    datasource "cp"
  </record>
</filter>

<match cp.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-cp-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
  </store>
  <store>
    @type kafka_buffered
    # docker
    # list of seed brokers
    brokers 172.16.6.11:9092,172.16.6.12:9092,172.16.6.13:9092
    # buffer settings
    buffer_type file
    buffer_path /data/log/td-agent/buffer/td
    flush_interval 3s

    # topic settings
    default_topic docker_message

    # data type settings
    output_data_type json
    include_time_key true
    include_tag_key true
    # compression_codec snappy

    # producer settings
    kafka_agg_max_bytes 40960
    max_send_retries 1
    required_acks 1
  </store>
  <store>
    @type flowcounter
    count_keys message
    unit hour
    tag fluentd.stats
  </store>
</match>

# ---------------------------------------------------------------
# baidubot
# ---------------------------------------------------------------
<filter bot.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    # 2018-02-22 17:58:47.862 ERROR 24 --- [nio-8080-exec-5] c.p.q.h.m.c.HotelListController          : ms_hotel | {"uid":"",xxx
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}.\d{3} \w+ \d/
    format1 /^(?<time>.{23}) +(?<level>[^ ]+) +(?<n_threads>\d+) +--- +\[(?<app_info>[^\]]+)\] +(?<class>[^ ]+) {0,}:(?<message>.*)/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<filter bot.sit>
  @type record_transformer
  <record>
    datasource "baidubot"
  </record>
</filter>

<match bot.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-cp-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
  </store>
</match>

# ---------------------------------------------------------------
# spring
# ---------------------------------------------------------------
<match spring.test>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name es-stats
    type_name sit-spring
    num_threads 1
    include_timestamp true
  </store>
  <store>
    @type stdout
  </store>
</match>

<filter app.spring.sit tsp.sit>
  @type concat
  key log
  stream_identity_key container_id
  # 2018-03-06 16:56:22.514 | mscparea | INFO  | http-nio-8080-exec-1 | com.pateo.qingcloud.cp.core.service.impl.CPBusiness.reflectAdapterRequest | 84: xxx
  multiline_start_regexp /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}\.\d{3} {0,}\|/
</filter>

<filter app.spring.sit tsp.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}\.\d{3} {0,}\|/
    format1 /^(?<time>.{23}) {0,}\| {0,}(?<app>[^ ]+) {0,}\| {0,}(?<level>[^ ]+) {0,}\| {0,}(?<thread>[^ ]+) {0,}\| {0,}(?<class>[^ ]+) {0,}\| {0,}(?<line>\d+) {0,}: {0,}(?<message>.*)/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<filter tsp.sit>
  @type record_transformer
  <record>
    datasource "tsp"
  </record>
</filter>

<filter app.spring.sit>
  @type record_transformer
  <record>
    datasource "spring"
  </record>
</filter>

<match app.spring.sit tsp.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-spring-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
  </store>

  <store>
    @type flowcounter
    count_keys message
    unit hour
    tag fluentd.stats
  </store>
</match>

# ---------------------------------------------------------------
# gateway
# ---------------------------------------------------------------
<match gateway.test>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name es-stats
    type_name sit-gateway
    num_threads 1
    include_timestamp true
  </store>
  <store>
    @type stdout
  </store>
</match>

<filter {gateway,connector}.sit>
  @type concat
  key log
  stream_identity_key container_id
  multiline_start_regexp /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}\.\d{3} {0,}\|/
</filter>

<filter connector.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    # 2018-04-02 02:02:10.928 | sh-datamining | INFO | http-nio-8080-exec-80 | com.pateo.qingcloud.gateway.core.zuul.filters.post.LogFilter | 74 | {"key": "value"}: xxx
    # 2018-04-02 02:02:10.928 | sh-datamining | INFO | http-nio-8080-exec-80 | com.pateo.qingcloud.gateway.core.zuul.filters.post.LogFilter | 74: xxx
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}\.\d{3} {0,}\|/
    format1 /^(?<time>.{23}) {0,}\| {0,}(?<app>[^ ]+) {0,}\| {0,}(?<level>[^ ]+) {0,}\| {0,}(?<thread>[^ ]+) {0,}\| {0,}(?<class>[^ ]+) {0,}\| {0,}(?<line>\d+) {0,}(\| {0,}(?<args>\{.*\}){0,1}){0,1}: {0,}(?<message>.*){0,1}/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<filter gateway.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    # 2018-03-12 02:02:10.928 | gateway | INFO | http-nio-8080-exec-80 | com.pateo.qingcloud.gateway.core.zuul.filters.post.LogFilter | 74: {"key": "value"}xxx
    # 2018-03-12 02:02:10.928 | gateway | INFO | http-nio-8080-exec-80 | com.pateo.qingcloud.gateway.core.zuul.filters.post.LogFilter | 74: {"key": "value"}
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}\.\d{3} {0,}\|/
    format1 /^(?<time>.{23}) {0,}\| {0,}(?<app>[^ ]+) {0,}\| {0,}(?<level>[^ ]+) {0,}\| {0,}(?<thread>[^ ]+) {0,}\| {0,}(?<class>[^ ]+) {0,}\| {0,}(?<line>\d+) {0,}: {0,}(?<args>\{[^\}]*\}){0,1}(?<message>.*){0,1}/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<filter {gateway,connector}.sit>
  @type parser
  key_name args
  reserve_data true
  format json
</filter>

<filter {gateway,connector}.sit>
  @type record_transformer
  remove_keys args
</filter>

<match {gateway,connector}.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-gateway-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
  </store>
  <store>
    @type flowcounter
    count_keys message
    unit hour
    tag fluentd.stats
  </store>
  # <store>
  #   @type stdout
  # </store>
</match>

# ---------------------------------------------------------------
# geely
# ---------------------------------------------------------------
<match geely.test>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name es-stats
    type_name sit-geely
    num_threads 1
    include_timestamp true
    # buffer
    # buffer_type file
    # flush_interval 5
    # buffer_path /data/log/td-agent/buffer/sit-log-geely
  </store>
  <store>
    @type stdout
  </store>
</match>

<filter geely.sit>
  @type concat
  key log
  stream_identity_key container_id
  # 2018-02-05 10:33:13.408 | geely:nlcc | INFO | http-bio-8081-exec-3 | com.tservice.cc.web.interceptor.MyLoggingOutInterceptor.handleMessage:57 - Outbound Message:{ID:1, Address:http://10.133.200.77:8082/gisnavi/tservice/gisnavi/poi/poicategory, Http-Method:GET, Content-Type:application/json, Headers:{Content-Type=[application/json], Accept=[application/json]}}
  multiline_start_regexp /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}.\d{3} +\|/
</filter>

<filter geely.sit>
  @type parser
  key_name log
  reserve_data false
  <parse>
    @type multiline
    format_firstline /^\d{4}-\d{2}-\d{2} +\d{2}:\d{2}:\d{2}.\d{3} +\|/
    format1 /^(?<time>.{23}) {0,}\| {0,}(?<project>[^ ]+) {0,}\| {0,}(?<level>[^ ]+) {0,}\| {0,}(?<thread>[^ ]+) {0,}\| {0,}(?<class>[^\:]+)\:(?<line>\d+) {0,}- {0,}(?<message>.+)/
    time_key time
    keep_time_key false
    time_format "%Y-%m-%d %H:%M:%S.%L"
    timezone +08:00
  </parse>
</filter>

<match geely.sit>
  @type copy
  <store>
    @type elasticsearch
    hosts es-server
    port 9200
    index_name sit-geely-logs
    type_name logs
    reload_connections false
    request_timeout 15s
    num_threads 2
    include_timestamp true
    # buffer
    # buffer_type file
    # buffer_path /data/log/td-agent/buffer/sit-log-spring-app
  </store>
  <store>
    @type flowcounter
    count_keys message
    unit hour
    tag fluentd.stats
  </store>
</match>

# ---------------------------------------------------------------
# others
# ---------------------------------------------------------------
<match fluentd.**>
  @type stdout
</match>

<match **>
  @type stdout  # discard
</match>
