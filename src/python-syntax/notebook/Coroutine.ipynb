{
 "metadata": {
  "name": "",
  "signature": "sha256:336246896ddb5620dc44c401ac5ffb8934371743c4647fc48d762cea1b802b51"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "import asyncio\n",
      "import urllib.request\n",
      "\n",
      "import aiohttp\n",
      "\n",
      "\n",
      "URLS = ['http://www.foxnews.com/',\n",
      "        'http://www.cnn.com/',\n",
      "        'http://europe.wsj.com/',\n",
      "        'http://www.bbc.co.uk/',\n",
      "        'http://some-made-up-domain.com/',\n",
      "        'http://www.baidu.com']\n",
      "\n",
      "\n",
      "@asyncio.coroutine\n",
      "def load_url(url):\n",
      "    response = yield from aiohttp.request('GET', url)\n",
      "    return (yield from response.read())\n",
      "\n",
      "\n",
      "@asyncio.coroutine\n",
      "def benchmark(url):\n",
      "    content = yield from load_url(url)\n",
      "    print('{} bytes from {} finished at {}'\n",
      "          .format(len(content), url, datetime.datetime.now()))\n",
      "\n",
      "\n",
      "start = datetime.datetime.now()\n",
      "loop = asyncio.get_event_loop()\n",
      "tasks = [\n",
      "    asyncio.async(benchmark(url)) for url in URLS\n",
      "]\n",
      "loop.run_until_complete(asyncio.wait(tasks))\n",
      "loop.close()\n",
      "print('all cost:', datetime.datetime.now() - start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "800 bytes from http://some-made-up-domain.com/ finished at 2014-11-06 16:06:31.668305\n",
        "81739 bytes from http://www.baidu.com finished at 2014-11-06 16:06:31.672282\n",
        "85938 bytes from http://www.foxnews.com/ finished at 2014-11-06 16:06:31.864946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "104566 bytes from http://www.bbc.co.uk/ finished at 2014-11-06 16:06:38.229060"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "124380 bytes from http://www.cnn.com/ finished at 2014-11-06 16:06:53.300190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "all cost: 0:00:21.678373\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ThreadPoolExecutor\n",
      "\n",
      "from pipe import as_list\n",
      "import time\n",
      "import concurrent.futures\n",
      "import urllib.request\n",
      "\n",
      "URLS = ['http://www.foxnews.com/',\n",
      "        'http://www.cnn.com/',\n",
      "        'http://europe.wsj.com/',\n",
      "        'http://www.bbc.co.uk/',\n",
      "        'http://some-made-up-domain.com/',\n",
      "        'http://www.baidu.com']\n",
      "\n",
      "# Retrieve a single page and report the url and contents\n",
      "def load_url(url, timeout):\n",
      "    conn = urllib.request.urlopen(url, timeout=timeout)\n",
      "    return conn.readall()\n",
      "\n",
      "\n",
      "start = datetime.datetime.now()\n",
      "# We can use a with statement to ensure threads are cleaned up promptly\n",
      "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
      "    # Start the load operations and mark each future with its URL\n",
      "    future_to_url = {executor.submit(load_url, url, 10): url for url in URLS}\n",
      "    \n",
      "    for future in concurrent.futures.as_completed(future_to_url):\n",
      "        url = future_to_url[future]\n",
      "        try:\n",
      "            data = future.result()\n",
      "        except Exception as exc:\n",
      "            print('%r generated an exception: %s' % (url, exc))\n",
      "        else:\n",
      "            print('%r page is %d bytes' % (url, len(data)))\n",
      "\n",
      "print('all cost', datetime.datetime.now() - start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'http://www.foxnews.com/' generated an exception: HTTP Error 404: Not Found\n",
        "'http://some-made-up-domain.com/' page is 800 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "'http://www.baidu.com' page is 81694 bytes\n",
        "'http://europe.wsj.com/' generated an exception: [Errno 54] Connection reset by peer"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "'http://www.bbc.co.uk/' page is 104566 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "'http://www.cnn.com/' page is 124380 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "all cost 0:00:30.468679\n"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}