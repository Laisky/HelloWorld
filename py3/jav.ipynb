{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc70584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# fetch by actress list by onejav\n",
    "# ------------------------------------------------\n",
    "# fetch_onejav_by_actress_list()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# fetch by actress list by javland\n",
    "# ------------------------------------------------\n",
    "# fetch_javland_by_actress_list()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# generate full text search metadata for each movie\n",
    "# ------------------------------------------------\n",
    "# generate_fulltext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc97e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from concurrent.futures import ALL_COMPLETED, ThreadPoolExecutor, wait\n",
    "from datetime import datetime\n",
    "from hashlib import sha256\n",
    "from io import BytesIO\n",
    "from queue import Queue\n",
    "from textwrap import dedent\n",
    "from typing import Generator, List, NamedTuple, Optional, Union, Dict\n",
    "\n",
    "import bson.json_util\n",
    "import pymongo\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bson import ObjectId\n",
    "from kipp.decorator import timer\n",
    "from kipp.utils import setup_logger\n",
    "from minio import Minio\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "logger = setup_logger(\"jav\")\n",
    "logger.setLevel(logging.INFO)\n",
    "executor = ThreadPoolExecutor(max_workers=100)\n",
    "\n",
    "\n",
    "sys.path.append(r\"/opt/configs/ramjet\")\n",
    "import prd\n",
    "\n",
    "# mongodb\n",
    "mongo = MongoClient(\n",
    "    f\"mongodb://{prd.MONGO_ADMIN_USER}:{prd.MONGO_ADMIN_PASSWD}@{prd.MONGO_HOST}:{prd.MONGO_PORT}\",\n",
    ")\n",
    "col_actress = mongo[\"jav\"][\"actress\"]\n",
    "col_movies = mongo[\"jav\"][\"movies\"]\n",
    "col_fulltext = mongo[\"jav\"][\"fulltext\"]\n",
    "\n",
    "\n",
    "# add index to db\n",
    "col_movies.create_index([(\"name\", pymongo.ASCENDING)])\n",
    "col_actress.create_index([(\"name\", pymongo.ASCENDING)])\n",
    "col_fulltext.create_index([(\"word\", pymongo.ASCENDING)], unique=True)\n",
    "\n",
    "# minio\n",
    "s3cli: Minio = Minio(\n",
    "    endpoint=prd.S3_MINIO_ADDR,\n",
    "    access_key=prd.S3_KEY,\n",
    "    secret_key=prd.S3_SECRET,\n",
    "    secure=True,\n",
    ")\n",
    "\n",
    "\n",
    "class Actress(NamedTuple):\n",
    "    # id is the unique id of the actress\n",
    "    id: ObjectId\n",
    "    # name is the name of the actress\n",
    "    name: str\n",
    "    # other_names is the other names of the actress, also contains the name\n",
    "    other_names: List[str]\n",
    "    # url is the url of the actress\n",
    "    url: str\n",
    "\n",
    "\n",
    "class Movie(NamedTuple):\n",
    "    # actresses is a list of actresses' id\n",
    "    actresses: List[ObjectId]\n",
    "    # name is the code of the movie\n",
    "    name: str\n",
    "    # description is the title of the movie\n",
    "    description: Optional[str]\n",
    "    # img_urls is a list of image urls that describe the movie\n",
    "    img_urls: List[str]\n",
    "    # tags is a list of tags that describe the movie\n",
    "    tags: List[str]\n",
    "    # published_date is the date when the movie is published\n",
    "    published_date: Optional[datetime]\n",
    "    # url is the url of the movie\n",
    "    urls: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31afa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# https://onejav.com/\n",
    "# =========================================\n",
    "\n",
    "actress_index_url = \"https://onejav.com/actress/\"\n",
    "\n",
    "REG_ONEJAV_ACTRESS_NAME = re.compile(r\"([\\w ]+)(?:<[^>]+>(\\w+).*)?\")\n",
    "\n",
    "\n",
    "@timer\n",
    "def gen_onejav_actress(q: Queue[Optional[Actress]]):\n",
    "    n_page = 1\n",
    "    n_retry = 0\n",
    "    while True:\n",
    "        url = f\"https://onejav.com/actress/?page={n_page}\"\n",
    "        logger.info(f\"gen_onejav_actress get actress for {url=}\")\n",
    "        resp = requests.get(url)\n",
    "        if resp.status_code == 500:\n",
    "            if n_retry < 3:\n",
    "                time.sleep(3)\n",
    "                logger.warning(f\"gen_onejav_actress retry {url=}, {n_retry=}\")\n",
    "                n_retry += 1\n",
    "                continue\n",
    "            else:\n",
    "                n_retry = 0\n",
    "                n_page += 1\n",
    "                continue\n",
    "        elif resp.status_code == 404:\n",
    "            logger.info(f\"gen_onejav_actress exit since for {url=}\")\n",
    "            return\n",
    "        elif resp.status_code != 200:\n",
    "            logger.info(\n",
    "                f\"gen_onejav_actress exit for {url=} [{resp.status_code}]{resp.text}\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        for card in soup.select(\".container .card\"):\n",
    "            name, url = \"\", \"\"\n",
    "\n",
    "            ele = card.select_one(\".card-header .card-header-title\")\n",
    "            assert ele, f\"cannot find actress name for {url=}\"\n",
    "            name = ele.decode_contents().strip()\n",
    "\n",
    "            ele = card.select_one(\"a\")\n",
    "            assert ele, f\"cannot find actress url for {url=}\"\n",
    "            url = f\"https://onejav.com{ele.attrs['href']}\"\n",
    "\n",
    "            # parse actress name\n",
    "            # name = 'Jun Suehiro <small class=\"text-muted ml-1\">末広純</small>'\n",
    "            [(alt_name, name)] = REG_ONEJAV_ACTRESS_NAME.findall(name)\n",
    "            name = name.strip()\n",
    "            alt_name = alt_name.strip()\n",
    "            name = name or alt_name\n",
    "\n",
    "            logger.debug(f\"yield actress {name}\")\n",
    "            actress = save_actress(name, url, list(set([name, alt_name])))\n",
    "            q.put(actress)\n",
    "\n",
    "        n_page += 1\n",
    "\n",
    "\n",
    "def save_actress(name: str, url: str, other_names: List[str]) -> Actress:\n",
    "    \"\"\"save actress to db, return actress_id\"\"\"\n",
    "    logger.info(f\"save actress {name}\")\n",
    "\n",
    "    col_actress.update_one(\n",
    "        {\"name\": name},\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"name\": name,\n",
    "                \"url\": url,\n",
    "                \"other_names\": other_names,\n",
    "            }\n",
    "        },\n",
    "        upsert=True,\n",
    "    )\n",
    "\n",
    "    docu = col_actress.find_one({\"name\": name})\n",
    "    assert docu, f\"can not find actress {name}\"\n",
    "    return Actress(\n",
    "        name=name,\n",
    "        url=url,\n",
    "        id=docu[\"_id\"],\n",
    "        other_names=docu[\"other_names\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def replace_image_url(movie_name: str, img_url: str) -> str:\n",
    "    \"\"\"download image and upload to s3, return new url\"\"\"\n",
    "    docu = col_movies.find_one({\"name\": movie_name})\n",
    "    if docu and docu[\"img_urls\"]:\n",
    "        return docu[\"img_urls\"][0]\n",
    "\n",
    "    resp = requests.get(img_url)\n",
    "    assert resp.status_code == 200\n",
    "\n",
    "    img_content = resp.content\n",
    "    digest = sha256(img_content).hexdigest()\n",
    "    objkey = f\"jav/{digest[:2]}/{digest[2:4]}/{digest}.png\"\n",
    "\n",
    "    # check whether image exists\n",
    "    new_img_url = f\"{prd.S3_SERVER}/public/{objkey}\"\n",
    "    if requests.head(new_img_url).status_code == 200:\n",
    "        return new_img_url\n",
    "\n",
    "    logger.info(f\"upload image to s3: {objkey}\")\n",
    "    s3cli.put_object(\n",
    "        bucket_name=\"public\",\n",
    "        object_name=objkey,\n",
    "        data=BytesIO(img_content),\n",
    "        length=len(img_content),\n",
    "        content_type=\"image/png\",\n",
    "    )\n",
    "\n",
    "    return new_img_url\n",
    "\n",
    "\n",
    "@timer\n",
    "def gen_onejav_movies_by_actress(upstream_q: Queue[Optional[Actress]]):\n",
    "    n_page = 1\n",
    "    n_retry = 0\n",
    "    while True:\n",
    "        actress = upstream_q.get()\n",
    "        if actress is None:\n",
    "            upstream_q.put(None)\n",
    "            logger.info(f\"gen_onejav_movies_by_actress exit\")\n",
    "            return\n",
    "\n",
    "        url = f\"{actress.url}?page={n_page}\"\n",
    "        resp = requests.get(url)\n",
    "        if resp.status_code % 100 == 5:\n",
    "            if n_retry < 3:\n",
    "                time.sleep(3)\n",
    "                logger.warning(f\"gen_movies retry {url=}, {n_retry=}\")\n",
    "                n_retry += 1\n",
    "                continue\n",
    "            else:\n",
    "                n_retry = 0\n",
    "                n_page += 1\n",
    "                continue\n",
    "        elif resp.status_code == 404:\n",
    "            logger.info(f\"gen_movies exit since for {url=}\")\n",
    "            return\n",
    "        elif resp.status_code != 200:\n",
    "            logger.info(\n",
    "                f\"gen_movies exit since for {url=} [{resp.status_code}]{resp.text}\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        for card in soup.select(\".container .card\"):\n",
    "            try:\n",
    "                ele = card.select_one(\".image\")\n",
    "                assert ele, f\"can not find image {url=}\"\n",
    "                img_url = ele.attrs[\"src\"]\n",
    "\n",
    "                ele = card.select_one(\".title a\")\n",
    "                assert ele, f\"can not find title {url=}\"\n",
    "                name = normalize_movie_name(ele.decode_contents())\n",
    "\n",
    "                description = None\n",
    "                if card.select_one(\".has-text-grey-dark\"):\n",
    "                    ele = card.select_one(\".has-text-grey-dark\")\n",
    "                    assert ele, f\"can not find description {url=}\"\n",
    "                    description = ele.decode_contents().strip()\n",
    "                tags = [\n",
    "                    ele.decode_contents().strip() for ele in card.select(\".tags .tag\")\n",
    "                ]\n",
    "\n",
    "                date: Optional[datetime] = None\n",
    "                ele = card.select_one(\".card-content .title .subtitle a\")\n",
    "                if ele and ele.attrs.get(\"href\"):\n",
    "                    # /2024/07/14\n",
    "                    date = datetime.strptime(ele.attrs[\"href\"], \"/%Y/%m/%d\")\n",
    "\n",
    "                img_url = replace_image_url(name, img_url)\n",
    "                movie = Movie(\n",
    "                    actresses=[actress.id],\n",
    "                    name=name,\n",
    "                    description=description,\n",
    "                    img_urls=[img_url],\n",
    "                    tags=tags,\n",
    "                    published_date=date,\n",
    "                    urls=[],\n",
    "                )\n",
    "                save_movie(movie)\n",
    "            except Exception:\n",
    "                logger.exception(f\"parse movie error {url=}\")\n",
    "                continue\n",
    "\n",
    "        n_page += 1\n",
    "\n",
    "\n",
    "REGEX_MOVIE_NAME = re.compile(r\"^([A-Z]+)(\\d+)$\")\n",
    "\n",
    "\n",
    "def normalize_movie_name(name: str) -> str:\n",
    "    name = name.upper().strip()\n",
    "    matched = REGEX_MOVIE_NAME.findall(name)\n",
    "    if matched:\n",
    "        prefix, num = matched[0]\n",
    "        if prefix and num:\n",
    "            name = f\"{prefix}-{num}\"\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def save_movie(movie: Movie):\n",
    "    \"\"\"save movie to db by movie name\"\"\"\n",
    "    movie_name = normalize_movie_name(movie.name)\n",
    "\n",
    "    img_urls = [v.strip() for v in movie.img_urls if v.strip()]\n",
    "    tags = [v.strip() for v in movie.tags if v.strip()]\n",
    "    actresses = [v for v in movie.actresses if v]\n",
    "    movie_urls = [v.strip() for v in movie.urls if v.strip()]\n",
    "\n",
    "    docu_to_set: Dict[str, Union[str, datetime]] = {\"name\": movie_name}\n",
    "    if movie.description:\n",
    "        docu_to_set[\"description\"] = movie.description\n",
    "    if movie.published_date:\n",
    "        docu_to_set[\"published_date\"] = movie.published_date\n",
    "\n",
    "    logger.info(f\"save movie {movie_name}\")\n",
    "    col_movies.update_one(\n",
    "        {\"name\": movie_name},\n",
    "        {\n",
    "            \"$set\": docu_to_set,\n",
    "            \"$addToSet\": {\n",
    "                \"actresses\": {\"$each\": actresses},\n",
    "                \"tags\": {\"$each\": tags},\n",
    "                \"img_urls\": {\"$each\": img_urls},\n",
    "                \"urls\": {\"$each\": movie_urls},\n",
    "            },\n",
    "        },\n",
    "        upsert=True,\n",
    "    )\n",
    "\n",
    "\n",
    "@timer\n",
    "def fetch_onejav_by_actress_list():\n",
    "    \"\"\"fetch actresses and movies by actress list and save to db\"\"\"\n",
    "    actress_queue = Queue(maxsize=10)\n",
    "\n",
    "    fs_load_actress = []\n",
    "    fs_load_movies = []\n",
    "\n",
    "    fs_load_actress.append(executor.submit(gen_onejav_actress, actress_queue))\n",
    "    for _ in range(20):\n",
    "        fs_load_movies.append(\n",
    "            executor.submit(gen_onejav_movies_by_actress, actress_queue)\n",
    "        )\n",
    "\n",
    "    wait(fs_load_actress, return_when=ALL_COMPLETED)\n",
    "    actress_queue.put(None)\n",
    "    wait(fs_load_movies, return_when=ALL_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82f7610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# https://jav.land/\n",
    "# =========================================\n",
    "\n",
    "actress_index_url = \"https://jav.land/ja/star_list.php?prefix={alphabet}&page={page}\"\n",
    "\n",
    "REGEX_JAVLAND_ACTRESS_NAME = re.compile(r\"(\\w+)(?:（(\\w+)(?:、(\\w+){0,}）))?\")\n",
    "\n",
    "\n",
    "class JavlandMovieInfo(NamedTuple):\n",
    "    actress: Actress\n",
    "    url: str\n",
    "    description: Optional[str]\n",
    "\n",
    "\n",
    "@timer\n",
    "def gen_javland_actress(q: Queue[Optional[Actress]]):\n",
    "    n_page = 1\n",
    "    alphabet = \"A\"\n",
    "    n_retry = 0\n",
    "    while alphabet <= \"Z\":\n",
    "        logger.info(f\"gen_javland_actress for {alphabet=}\")\n",
    "        while True:\n",
    "            url = actress_index_url.format(alphabet=alphabet, page=n_page)\n",
    "            try:\n",
    "                logger.info(f\"request actress {url=}\")\n",
    "                resp = requests.get(url)\n",
    "                if resp.status_code % 100 == 5:\n",
    "                    if n_retry < 3:\n",
    "                        time.sleep(3)\n",
    "                        logger.warn(f\"gen_javland_actress retry {url=}, {n_retry=}\")\n",
    "                        n_retry += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        n_retry = 0\n",
    "                        n_page += 1\n",
    "                        continue\n",
    "                elif resp.status_code == 404:\n",
    "                    logger.info(f\"gen_javland_actress exit since for {url=}\")\n",
    "                    break\n",
    "                elif resp.status_code != 200:\n",
    "                    logger.info(\n",
    "                        f\"gen_javland_actress exit for {url=} [{resp.status_code}]{resp.text}\"\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "                soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "                cards = soup.select(\".container-fluid .genre_list a.text-center\")\n",
    "                if not cards:\n",
    "                    break\n",
    "\n",
    "                for card in cards:\n",
    "                    raw_name = card.decode_contents().strip()\n",
    "\n",
    "                    # parse actress name\n",
    "                    # name = \"馬場ふみか\" / ayami（赤西涼、まひる）\n",
    "                    matched = REGEX_JAVLAND_ACTRESS_NAME.findall(raw_name)\n",
    "                    assert matched, f\"can not parse actress name {raw_name=}\"\n",
    "                    assert matched[0], f\"can not parse actress name {raw_name=}\"\n",
    "                    other_names = list(\n",
    "                        set([v.strip() for v in matched[0] if v.strip()])\n",
    "                    )\n",
    "                    name = other_names[0]\n",
    "                    assert name, f\"can not parse actress name {raw_name=}\"\n",
    "\n",
    "                    actress_url = f\"https://jav.land{card.attrs['href']}\"\n",
    "\n",
    "                    logger.debug(f\"yield actress {name}\")\n",
    "                    actress = save_actress(name, actress_url, other_names)\n",
    "                    q.put(actress)\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "                logger.exception(f\"gen_javland_actress error {url=}\")\n",
    "                continue\n",
    "\n",
    "            n_page += 1\n",
    "\n",
    "        n_page = 1\n",
    "        alphabet = chr(ord(alphabet) + 1)\n",
    "\n",
    "\n",
    "@timer\n",
    "def gen_javland_movies_by_actress(\n",
    "    upstream_q: Queue[Optional[Actress]],\n",
    "    downstream_q: Queue[Optional[JavlandMovieInfo]],\n",
    "):\n",
    "    while True:\n",
    "        actress = upstream_q.get()\n",
    "        if actress is None:\n",
    "            upstream_q.put(None)\n",
    "            logger.info(f\"gen_javland_movies_by_actress exit\")\n",
    "            return\n",
    "\n",
    "        n_page = 1\n",
    "        n_retry = 0\n",
    "        while True:\n",
    "            url = f\"{actress.url}?page={n_page}\"\n",
    "            try:\n",
    "                logger.info(f\"request movies for {url=}\")\n",
    "                resp = requests.get(url)\n",
    "                if resp.status_code % 100 == 5:\n",
    "                    if n_retry < 3:\n",
    "                        time.sleep(3)\n",
    "                        logger.warn(f\"gen_movies retry {url=}, {n_retry=}\")\n",
    "                        n_retry += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        n_retry = 0\n",
    "                        n_page += 1\n",
    "                        continue\n",
    "                elif resp.status_code == 404:\n",
    "                    logger.info(f\"gen_movies exit since for {url=}\")\n",
    "                    break\n",
    "                elif resp.status_code != 200:\n",
    "                    logger.warn(\n",
    "                        f\"gen_movies skip since for {url=} [{resp.status_code}]{resp.text}\"\n",
    "                    )\n",
    "                    n_page += 1\n",
    "                    continue\n",
    "\n",
    "                soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "                cards = soup.select(\".container-fluid .videothumblist .video.panel\")\n",
    "                if not cards:\n",
    "                    logger.info(f\"can not find cards for {url=}\")\n",
    "                    break\n",
    "\n",
    "                for card in cards:\n",
    "                    ele = card.select_one(\".panel-footer a\")\n",
    "                    assert ele, f\"can not find url {url=}\"\n",
    "                    url = f\"https://jav.land{ele.attrs['href']}\"\n",
    "                    description = ele.decode_contents().strip()\n",
    "\n",
    "                    downstream_q.put(\n",
    "                        JavlandMovieInfo(\n",
    "                            actress=actress, url=url, description=description\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                n_page += 1\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "                logger.exception(f\"gen_javland_movies_by_actress got error for {url=}\")\n",
    "\n",
    "\n",
    "@timer\n",
    "def fetch_javland_movie(q: Queue[Optional[JavlandMovieInfo]]):\n",
    "    while True:\n",
    "        movie_info = q.get()\n",
    "        if movie_info is None:\n",
    "            q.put(None)\n",
    "            logger.info(f\"fetch_javland_movie exit\")\n",
    "            return\n",
    "\n",
    "        nretry = 0\n",
    "        while nretry < 3:\n",
    "            try:\n",
    "                logger.debug(f\"fetch movie for {movie_info.url=}\")\n",
    "                resp = requests.get(\n",
    "                    movie_info.url,\n",
    "                    headers={\n",
    "                        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "                        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "                    },\n",
    "                )\n",
    "                if resp.status_code != 200:\n",
    "                    logger.warning(\n",
    "                        f\"fetch_javland_movie error, {movie_info.url=} [{resp.status_code}]{resp.text}\"\n",
    "                    )\n",
    "                    time.sleep(3)\n",
    "                    nretry += 1\n",
    "                    continue\n",
    "\n",
    "                soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "                name: str = \"\"\n",
    "                tags: List[str] = []\n",
    "                date: Optional[datetime] = None\n",
    "                rows = soup.select(\".k-right .videotextlist tr\")\n",
    "                for row in rows:\n",
    "                    ele = row.select_one(\"td:nth-child(1)\")\n",
    "                    key: str = \"\"\n",
    "                    value: str = \"\"\n",
    "\n",
    "                    if ele:\n",
    "                        key = ele.decode_contents().strip()\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    ele = row.select_one(\"td:nth-child(2)\")\n",
    "                    if ele:\n",
    "                        value = ele.decode_contents().strip()\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if \"DVD ID\" in key:\n",
    "                        name = normalize_movie_name(value)\n",
    "                    elif \"ジャンル\" in key:\n",
    "                        vals = row.select(\"td:nth-child(2) .genre a\")\n",
    "                        tags = list(\n",
    "                            set([val.decode_contents().strip() for val in vals])\n",
    "                        )\n",
    "                    elif \"発売日\" in key:\n",
    "                        date = datetime.strptime(value, \"%Y-%m-%d\")\n",
    "\n",
    "                ele = soup.select_one(\".k-right img.img-responsive\")\n",
    "                assert ele, f\"can not find image {movie_info.url=}\"\n",
    "                img_url = ele.attrs[\"src\"]\n",
    "                img_url = replace_image_url(name, img_url)\n",
    "\n",
    "                movie = Movie(\n",
    "                    actresses=[movie_info.actress.id],\n",
    "                    name=name,\n",
    "                    description=movie_info.description,\n",
    "                    img_urls=[img_url],\n",
    "                    tags=tags,\n",
    "                    published_date=date,\n",
    "                    urls=[movie_info.url],\n",
    "                )\n",
    "                save_movie(movie)\n",
    "                break\n",
    "            except Exception:\n",
    "                nretry += 1\n",
    "                time.sleep(3)\n",
    "                logger.exception(f\"fetch_javland_movie error {movie_info.url=}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "@timer\n",
    "def fetch_javland_by_actress_list():\n",
    "    \"\"\"fetch actresses and movies by actress list and save to db\"\"\"\n",
    "    actress_queue = Queue(maxsize=10)\n",
    "    movie_queue = Queue(maxsize=10)\n",
    "\n",
    "    fs_load_actress = []\n",
    "    fs_load_movies = []\n",
    "    fs_save_movies = []\n",
    "\n",
    "    fs_load_actress.append(executor.submit(gen_javland_actress, actress_queue))\n",
    "    for _ in range(10):\n",
    "        fs_load_movies.append(\n",
    "            executor.submit(gen_javland_movies_by_actress, actress_queue, movie_queue)\n",
    "        )\n",
    "        fs_save_movies.append(executor.submit(fetch_javland_movie, movie_queue))\n",
    "\n",
    "    wait(fs_load_actress, return_when=ALL_COMPLETED)\n",
    "    actress_queue.put(None)\n",
    "    wait(fs_load_movies, return_when=ALL_COMPLETED)\n",
    "    movie_queue.put(None)\n",
    "    wait(fs_save_movies, return_when=ALL_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b05bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = dedent(\n",
    "#     \"\"\"\n",
    "#     You play the role of a tokenization engine. Execute the following instructions step by step and provide the output of each step.\n",
    "\n",
    "#     1. Read the user's input, extract the most important keywords based on your understanding, Output these words separated by commas.\n",
    "\n",
    "#     2. Create an expanded JSON array based on the original one. Keep the original array intact and translate any non-English words into English, adding those translations to the end of the original array.\n",
    "\n",
    "#     3. Present the final result as a JSON array, Please strictly output in the following format, without adding any other characters:\n",
    "\n",
    "#         result: [\"word-1\", \"word-2\"].\n",
    "#     \"\"\"\n",
    "# )\n",
    "# user_prompt = \"焦らし寸止め絶頂セックス あやみ史上1番エロいです！あやみはまだまだ進化しています！ ACT.03 あやみ旬果\"\n",
    "\n",
    "# resp = llm_oneshot_gemma(system_prompt, user_prompt)\n",
    "# print(resp)\n",
    "\n",
    "# matched = REGEX_SEGMENT_RESULT.findall(resp)\n",
    "# print(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9bd0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# generate full text search metadata for each movie\n",
    "# =========================================\n",
    "\n",
    "\n",
    "def llm_oneshot(model: str, system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"get response from LLM\"\"\"\n",
    "    url = f\"{prd.OPENAI_API}/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {prd.OPENAI_TOKEN}\",\n",
    "    }\n",
    "    body = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 3000,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=body)\n",
    "    assert resp.status_code == 200, f\"[{resp.status_code}]{resp.text}\"\n",
    "\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "GEMMA_API = \"http://100.92.237.35:7861/chat/completions\"\n",
    "\n",
    "\n",
    "def llm_oneshot_gemma(system_prompt: str, user_prompt: str) -> str:\n",
    "    body = {\n",
    "        \"model\": \"gemma-2b-it\",\n",
    "        \"max_tokens\": 3000,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            # gemma does not support `system_prompt`\n",
    "            {\"role\": \"user\", \"content\": f\"{system_prompt}\\n>>\\n{user_prompt}\"},\n",
    "        ],\n",
    "    }\n",
    "    resp = requests.post(GEMMA_API, json=body)\n",
    "    assert resp.status_code == 200, f\"[{resp.status_code}]{resp.text}\"\n",
    "    return resp.json()[\"completion\"]\n",
    "\n",
    "\n",
    "REGEX_SEGMENT_RESULT = re.compile(r\"result\\\"?: (\\[[^\\]]*\\])\")\n",
    "\n",
    "\n",
    "def segment_word(sentence: str) -> List[str]:\n",
    "    \"\"\"segment sentence to words\"\"\"\n",
    "    system_prompt = dedent(\n",
    "        \"\"\"\n",
    "        You play the role of a tokenization engine. Execute the following instructions step by step and provide the output of each step.\n",
    "\n",
    "        1. Read the user's input, extract the most important keywords based on your understanding, Output these words separated by commas.\n",
    "\n",
    "        2. Create an expanded JSON array based on the original one. Keep the original array intact and translate any non-English words into English, adding those translations to the end of the original array.\n",
    "\n",
    "        3. Present the final result as a JSON array, Please strictly output in the following format, without adding any other characters:\n",
    "\n",
    "            result: [\"word-1\", \"word-2\"].\n",
    "        \"\"\"\n",
    "    )\n",
    "    user_prompt = sentence\n",
    "\n",
    "    # resp = llm_oneshot(\"deepseek-chat\", system_prompt, user_prompt)\n",
    "    resp = llm_oneshot_gemma(system_prompt, user_prompt)\n",
    "\n",
    "    matched = REGEX_SEGMENT_RESULT.findall(resp)\n",
    "    assert matched, f\"invalid format of response {resp=}\"\n",
    "\n",
    "    try:\n",
    "        words = json.loads(matched[-1])\n",
    "    except Exception:\n",
    "        logger.error(f\"json loads {matched=}\")\n",
    "        raise\n",
    "\n",
    "    assert isinstance(words, list), f\"invalid response {words=} parsed from {resp=}\"\n",
    "\n",
    "    words = [word.strip() for word in words if isinstance(word, str) and word.strip()]\n",
    "    words = list(set(words))\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "@timer\n",
    "def _list_movies_in_db(q: Queue[Movie]):\n",
    "    for docu in col_movies.find():\n",
    "        movie = Movie(\n",
    "            actresses=docu[\"actresses\"],\n",
    "            name=docu[\"name\"],\n",
    "            description=docu[\"description\"],\n",
    "            img_urls=docu[\"img_urls\"],\n",
    "            tags=docu[\"tags\"],\n",
    "            published_date=docu.get(\"published_date\"),\n",
    "            urls=docu.get(\"urls\"),\n",
    "        )\n",
    "        q.put(movie)\n",
    "\n",
    "\n",
    "class FulltextItem(NamedTuple):\n",
    "    movie_id: ObjectId\n",
    "    word: str\n",
    "\n",
    "\n",
    "@timer\n",
    "def _generate_fulltext_for_movie(\n",
    "    upstream_q: Queue[Optional[Movie]], downstream_q: Queue[FulltextItem]\n",
    "):\n",
    "    \"\"\"generate fulltext for each movie, each word points to a movie\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            movie = upstream_q.get()\n",
    "            if movie is None:\n",
    "                upstream_q.put(None)\n",
    "                logger.info(f\"_generate_fulltext_for_movie exit\")\n",
    "                return\n",
    "\n",
    "            keywords: List[str] = [movie.name]\n",
    "            keywords.extend(movie.tags)\n",
    "\n",
    "            # load movie\n",
    "            logger.info(f\"_generate_fulltext_for_movie for {movie.name=}\")\n",
    "            movie_docu = col_movies.find_one({\"name\": movie.name})\n",
    "            assert movie_docu, f\"can not find movie {movie.name}\"\n",
    "\n",
    "            # load actress\n",
    "            for docu in col_actress.find({\"_id\": {\"$in\": movie_docu[\"actresses\"]}}):\n",
    "                keywords.extend(docu.get(\"other_names\", []))\n",
    "\n",
    "            keywords = list(set(keywords))\n",
    "\n",
    "            # tobe_segment = f\"{','.join(keywords)}, {movie_docu.get('description', '')}\"\n",
    "            # movie_words = segment_word(tobe_segment)\n",
    "            # keywords.extend(movie_words)\n",
    "\n",
    "            keywords = list(set(keywords))\n",
    "            for word in keywords:\n",
    "                downstream_q.put(FulltextItem(movie_id=movie_docu[\"_id\"], word=word))\n",
    "        except Exception:\n",
    "            logger.exception(f\"error in _generate_fulltext_for_movie\")\n",
    "\n",
    "\n",
    "@timer\n",
    "def _save_fulltext_item(q: Queue[Optional[FulltextItem]]):\n",
    "    \"\"\"save fulltext item to db, each word may points to multiple movies\"\"\"\n",
    "    last_movie_id: Optional[ObjectId] = None\n",
    "    while True:\n",
    "        try:\n",
    "            item = q.get()\n",
    "            if item is None:\n",
    "                q.put(None)\n",
    "                logger.info(f\"_save_fulltext_item exit\")\n",
    "                return\n",
    "\n",
    "            if item.movie_id != last_movie_id:\n",
    "                col_movies.update_one(\n",
    "                    {\"_id\": last_movie_id},\n",
    "                    {\"$set\": {\"fulltext_updated_at\": datetime.now()}},\n",
    "                )\n",
    "                last_movie_id = item.movie_id\n",
    "\n",
    "            # each word may points to multiple movies,\n",
    "            # these movies are stored in a set\n",
    "            col_fulltext.update_one(\n",
    "                {\"word\": item.word},\n",
    "                {\"$addToSet\": {\"movies\": item.movie_id}},\n",
    "                upsert=True,\n",
    "            )\n",
    "        except Exception:\n",
    "            logger.exception(f\"error in _save_fulltext_item\")\n",
    "\n",
    "\n",
    "@timer\n",
    "def generate_fulltext():\n",
    "    movie_queue = Queue(maxsize=10)\n",
    "    fulltext_queue = Queue(maxsize=10)\n",
    "\n",
    "    fs_list_movies = []\n",
    "    fs_generate_fulltext = []\n",
    "    fs_save_fulltext = []\n",
    "\n",
    "    fs_list_movies.append(executor.submit(_list_movies_in_db, movie_queue))\n",
    "    for i in range(40):\n",
    "        fs_generate_fulltext.append(\n",
    "            executor.submit(_generate_fulltext_for_movie, movie_queue, fulltext_queue)\n",
    "        )\n",
    "        fs_save_fulltext.append(executor.submit(_save_fulltext_item, fulltext_queue))\n",
    "\n",
    "    wait(fs_list_movies, return_when=ALL_COMPLETED)\n",
    "    movie_queue.put(None)\n",
    "    wait(fs_generate_fulltext, return_when=ALL_COMPLETED)\n",
    "    fulltext_queue.put(None)\n",
    "    wait(fs_save_fulltext, return_when=ALL_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7bc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEX_MOVIE_NAME = re.compile(r\"^([A-Z]+)(\\d+)$\")\n",
    "\n",
    "\n",
    "def convert_movies():\n",
    "    # remove empty images\n",
    "    for docu in col_movies.find({\"img_urls\": \"\"}):\n",
    "        imgs = [v for v in docu[\"img_urls\"] if v.strip()]\n",
    "        col_movies.update_one(\n",
    "            {\"_id\": docu[\"_id\"]},\n",
    "            {\"$set\": {\"img_urls\": imgs}},\n",
    "        )\n",
    "\n",
    "\n",
    "# convert_movies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
