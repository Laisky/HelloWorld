{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "537d6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# openai tokens\n",
    "# ====================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "import pickle\n",
    "import re\n",
    "import textwrap\n",
    "from collections import namedtuple\n",
    "\n",
    "import faiss\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, MarkdownTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"/opt/configs/ramjet\")\n",
    "import prd\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = prd.OPENAI_TOKEN_ME\n",
    "\n",
    "\n",
    "Index = namedtuple(\"index\", [\"store\", \"scaned_files\"])\n",
    "\n",
    "\n",
    "def pretty_print(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    return textwrap.fill(text, width=60, subsequent_indent=\"    \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e68c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# prepare pdf documents docs.index & docs.store\n",
    "#\n",
    "# https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html#retain-elements\n",
    "#\n",
    "# 通用的函数定义\n",
    "# ==============================================================\n",
    "\n",
    "from urllib.parse import quote\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, MarkdownTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, separator=\"\\n\")\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "N_BACTCH_FILES = 5\n",
    "\n",
    "\n",
    "def is_file_scaned(index: Index, fpath):\n",
    "    return os.path.split(fpath)[1] in index.scaned_files\n",
    "\n",
    "\n",
    "def embedding_pdfs(index: Index, fpaths, url, replace_by_url):\n",
    "    i = 0\n",
    "    docs = []\n",
    "    metadatas = []\n",
    "    for fpath in fpaths:\n",
    "        fname = os.path.split(fpath)[1]\n",
    "        if is_file_scaned(index, fname):\n",
    "            continue\n",
    "\n",
    "        loader = PyPDFLoader(fpath)\n",
    "        for page, data in enumerate(loader.load_and_split()):\n",
    "            splits = text_splitter.split_text(data.page_content)\n",
    "            docs.extend(splits)\n",
    "            for ichunk, _ in enumerate(splits):\n",
    "                fnameurl = quote(fpath.removeprefix(replace_by_url), safe=\"\")\n",
    "                furl = url + fnameurl\n",
    "                metadatas.append({\"source\": f\"{furl}#page={page+1}\"})\n",
    "\n",
    "        index.scaned_files.add(fname)\n",
    "        print(f\"scaned {fpath}\")\n",
    "        i += 1\n",
    "        if i > N_BACTCH_FILES:\n",
    "            break\n",
    "\n",
    "    if i != 0:\n",
    "        index.store.add_texts(docs, metadatas=metadatas)\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def embedding_markdowns(index: Index, fpaths, url, replace_by_url):\n",
    "    i = 0\n",
    "    docs = []\n",
    "    metadatas = []\n",
    "    for fpath in fpaths:\n",
    "        fname = os.path.split(fpath)[1]\n",
    "        if is_file_scaned(index, fpath):\n",
    "            continue\n",
    "\n",
    "        with codecs.open(fpath, \"rb\", \"utf8\") as fp:\n",
    "            docus = markdown_splitter.create_documents([fp.read()])\n",
    "            for ichunk, docu in enumerate(docus):\n",
    "                docs.append(docu.page_content)\n",
    "                title = quote(docu.page_content.strip().split(\"\\n\", maxsplit=1)[0])\n",
    "                if url:\n",
    "                    fnameurl = quote(fpath.removeprefix(replace_by_url), safe=\"\")\n",
    "                    furl = url + fnameurl\n",
    "                    metadatas.append({\"source\": f\"{furl}#{title}\"})\n",
    "                else:\n",
    "                    metadatas.append({\"source\": f\"{fname}#{title}\"})\n",
    "                    \n",
    "        index.scaned_files.add(fname)\n",
    "        print(f\"scaned {fpath}\")\n",
    "        i += 1\n",
    "        if i > N_BACTCH_FILES:\n",
    "            break\n",
    "\n",
    "    if i != 0:\n",
    "        index.store.add_texts(docs, metadatas=metadatas)\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def load_store(dirpath, name) -> Index:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dirpath: dirpath to store index files\n",
    "        name: project/file name\n",
    "    \"\"\"\n",
    "    index = faiss.read_index(f\"{os.path.join(dirpath, name)}.index\")\n",
    "    with open(f\"{os.path.join(dirpath, name)}.store\", \"rb\") as f:\n",
    "        store = pickle.load(f)\n",
    "    store.index = index\n",
    "\n",
    "    with open(f\"{os.path.join(dirpath, name)}.scanedfile\", \"rb\") as f:\n",
    "        scaned_files = pickle.load(f)\n",
    "\n",
    "    return Index(\n",
    "        store=store,\n",
    "        scaned_files=scaned_files,\n",
    "    )\n",
    "\n",
    "\n",
    "def new_store() -> Index:\n",
    "    store = FAISS.from_texts([\"world\"], OpenAIEmbeddings(), metadatas=[{\"source\": \"hello\"}])\n",
    "    return Index(\n",
    "        store=store,\n",
    "        scaned_files=set([]),\n",
    "    )\n",
    "\n",
    "\n",
    "def save_store(index: Index, dirpath, name):\n",
    "    store_index = index.store.index\n",
    "    fpath_prefix = os.path.join(dirpath, name)\n",
    "    print(f\"save store to {fpath_prefix}\")\n",
    "    faiss.write_index(store_index, f\"{fpath_prefix}.index\")\n",
    "    index.store.index = None\n",
    "    with open(f\"{fpath_prefix}.store\", \"wb\") as f:\n",
    "        pickle.dump(index.store, f)\n",
    "    index.store.index = store_index\n",
    "\n",
    "    with open(f\"{fpath_prefix}.scanedfile\", \"wb\") as f:\n",
    "        pickle.dump(index.scaned_files, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488aba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 533, which is longer than the specified 500\n",
      "Created a chunk of size 523, which is longer than the specified 500\n",
      "Created a chunk of size 602, which is longer than the specified 500\n",
      "Created a chunk of size 598, which is longer than the specified 500\n",
      "Created a chunk of size 611, which is longer than the specified 500\n",
      "Created a chunk of size 648, which is longer than the specified 500\n",
      "Created a chunk of size 609, which is longer than the specified 500\n",
      "Created a chunk of size 547, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 647, which is longer than the specified 500\n",
      "Created a chunk of size 642, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 742, which is longer than the specified 500\n",
      "Created a chunk of size 508, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 512, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 557, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 508, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaned /home/laisky/data/langchain/pdf/security/Brian Ward - How Linux Works (2021, No Starch Press).pdf\n",
      "scaned /home/laisky/data/langchain/pdf/security/Computer Security Art And Science_Matt Bishop, Elisabeth Sullivan etc.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 514, which is longer than the specified 500\n",
      "Created a chunk of size 551, which is longer than the specified 500\n",
      "Created a chunk of size 706, which is longer than the specified 500\n",
      "Created a chunk of size 733, which is longer than the specified 500\n",
      "Created a chunk of size 947, which is longer than the specified 500\n",
      "Created a chunk of size 567, which is longer than the specified 500\n",
      "Created a chunk of size 760, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 644, which is longer than the specified 500\n",
      "Created a chunk of size 664, which is longer than the specified 500\n",
      "Created a chunk of size 547, which is longer than the specified 500\n",
      "Created a chunk of size 713, which is longer than the specified 500\n",
      "Created a chunk of size 1035, which is longer than the specified 500\n",
      "Created a chunk of size 796, which is longer than the specified 500\n",
      "Created a chunk of size 651, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 968, which is longer than the specified 500\n",
      "Created a chunk of size 765, which is longer than the specified 500\n",
      "Created a chunk of size 663, which is longer than the specified 500\n",
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 987, which is longer than the specified 500\n",
      "Created a chunk of size 523, which is longer than the specified 500\n",
      "Created a chunk of size 685, which is longer than the specified 500\n",
      "Created a chunk of size 597, which is longer than the specified 500\n",
      "Created a chunk of size 859, which is longer than the specified 500\n",
      "Created a chunk of size 644, which is longer than the specified 500\n",
      "Created a chunk of size 919, which is longer than the specified 500\n",
      "Created a chunk of size 809, which is longer than the specified 500\n",
      "Created a chunk of size 515, which is longer than the specified 500\n",
      "Created a chunk of size 541, which is longer than the specified 500\n",
      "Created a chunk of size 1315, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 609, which is longer than the specified 500\n",
      "Created a chunk of size 505, which is longer than the specified 500\n",
      "Created a chunk of size 555, which is longer than the specified 500\n",
      "Created a chunk of size 561, which is longer than the specified 500\n",
      "Created a chunk of size 793, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 717, which is longer than the specified 500\n",
      "Created a chunk of size 871, which is longer than the specified 500\n",
      "Created a chunk of size 787, which is longer than the specified 500\n",
      "Created a chunk of size 940, which is longer than the specified 500\n",
      "Created a chunk of size 952, which is longer than the specified 500\n",
      "Created a chunk of size 579, which is longer than the specified 500\n",
      "Created a chunk of size 682, which is longer than the specified 500\n",
      "Created a chunk of size 677, which is longer than the specified 500\n",
      "Created a chunk of size 566, which is longer than the specified 500\n",
      "Created a chunk of size 657, which is longer than the specified 500\n",
      "Created a chunk of size 556, which is longer than the specified 500\n",
      "Created a chunk of size 877, which is longer than the specified 500\n",
      "Created a chunk of size 554, which is longer than the specified 500\n",
      "Created a chunk of size 523, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 847, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 687, which is longer than the specified 500\n",
      "Created a chunk of size 558, which is longer than the specified 500\n",
      "Created a chunk of size 725, which is longer than the specified 500\n",
      "Created a chunk of size 532, which is longer than the specified 500\n",
      "Created a chunk of size 825, which is longer than the specified 500\n",
      "Created a chunk of size 617, which is longer than the specified 500\n",
      "Created a chunk of size 753, which is longer than the specified 500\n",
      "Created a chunk of size 639, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 691, which is longer than the specified 500\n",
      "Created a chunk of size 570, which is longer than the specified 500\n",
      "Created a chunk of size 1058, which is longer than the specified 500\n",
      "Created a chunk of size 631, which is longer than the specified 500\n",
      "Created a chunk of size 690, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 682, which is longer than the specified 500\n",
      "Created a chunk of size 597, which is longer than the specified 500\n",
      "Created a chunk of size 524, which is longer than the specified 500\n",
      "Created a chunk of size 544, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 1032, which is longer than the specified 500\n",
      "Created a chunk of size 678, which is longer than the specified 500\n",
      "Created a chunk of size 555, which is longer than the specified 500\n",
      "Created a chunk of size 551, which is longer than the specified 500\n",
      "Created a chunk of size 578, which is longer than the specified 500\n",
      "Created a chunk of size 1127, which is longer than the specified 500\n",
      "Created a chunk of size 565, which is longer than the specified 500\n",
      "Created a chunk of size 520, which is longer than the specified 500\n",
      "Created a chunk of size 540, which is longer than the specified 500\n",
      "Created a chunk of size 803, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 806, which is longer than the specified 500\n",
      "Created a chunk of size 787, which is longer than the specified 500\n",
      "Created a chunk of size 669, which is longer than the specified 500\n",
      "Created a chunk of size 653, which is longer than the specified 500\n",
      "Created a chunk of size 791, which is longer than the specified 500\n",
      "Created a chunk of size 571, which is longer than the specified 500\n",
      "Created a chunk of size 758, which is longer than the specified 500\n",
      "Created a chunk of size 669, which is longer than the specified 500\n",
      "Created a chunk of size 652, which is longer than the specified 500\n",
      "Created a chunk of size 582, which is longer than the specified 500\n",
      "Created a chunk of size 886, which is longer than the specified 500\n",
      "Created a chunk of size 572, which is longer than the specified 500\n",
      "Created a chunk of size 502, which is longer than the specified 500\n",
      "Created a chunk of size 592, which is longer than the specified 500\n",
      "Created a chunk of size 642, which is longer than the specified 500\n",
      "Created a chunk of size 723, which is longer than the specified 500\n",
      "Created a chunk of size 622, which is longer than the specified 500\n",
      "Created a chunk of size 701, which is longer than the specified 500\n",
      "Created a chunk of size 581, which is longer than the specified 500\n",
      "Created a chunk of size 558, which is longer than the specified 500\n",
      "Created a chunk of size 1149, which is longer than the specified 500\n",
      "Created a chunk of size 782, which is longer than the specified 500\n",
      "Created a chunk of size 791, which is longer than the specified 500\n",
      "Created a chunk of size 763, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 618, which is longer than the specified 500\n",
      "Created a chunk of size 549, which is longer than the specified 500\n",
      "Created a chunk of size 516, which is longer than the specified 500\n",
      "Created a chunk of size 647, which is longer than the specified 500\n",
      "Created a chunk of size 660, which is longer than the specified 500\n",
      "Created a chunk of size 593, which is longer than the specified 500\n",
      "Created a chunk of size 634, which is longer than the specified 500\n",
      "Created a chunk of size 948, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 534, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 558, which is longer than the specified 500\n",
      "Created a chunk of size 567, which is longer than the specified 500\n",
      "Created a chunk of size 571, which is longer than the specified 500\n",
      "Created a chunk of size 581, which is longer than the specified 500\n",
      "Created a chunk of size 628, which is longer than the specified 500\n",
      "Created a chunk of size 618, which is longer than the specified 500\n",
      "Created a chunk of size 607, which is longer than the specified 500\n",
      "Created a chunk of size 543, which is longer than the specified 500\n",
      "Created a chunk of size 800, which is longer than the specified 500\n",
      "Created a chunk of size 652, which is longer than the specified 500\n",
      "Created a chunk of size 554, which is longer than the specified 500\n",
      "Created a chunk of size 645, which is longer than the specified 500\n",
      "Created a chunk of size 711, which is longer than the specified 500\n",
      "Created a chunk of size 515, which is longer than the specified 500\n",
      "Created a chunk of size 526, which is longer than the specified 500\n",
      "Created a chunk of size 526, which is longer than the specified 500\n",
      "Created a chunk of size 541, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 877, which is longer than the specified 500\n",
      "Created a chunk of size 533, which is longer than the specified 500\n",
      "Created a chunk of size 745, which is longer than the specified 500\n",
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 720, which is longer than the specified 500\n",
      "Created a chunk of size 915, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 612, which is longer than the specified 500\n",
      "Created a chunk of size 652, which is longer than the specified 500\n",
      "Created a chunk of size 586, which is longer than the specified 500\n",
      "Created a chunk of size 706, which is longer than the specified 500\n",
      "Created a chunk of size 629, which is longer than the specified 500\n",
      "Created a chunk of size 543, which is longer than the specified 500\n",
      "Created a chunk of size 578, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 1150, which is longer than the specified 500\n",
      "Created a chunk of size 595, which is longer than the specified 500\n",
      "Created a chunk of size 636, which is longer than the specified 500\n",
      "Created a chunk of size 648, which is longer than the specified 500\n",
      "Created a chunk of size 505, which is longer than the specified 500\n",
      "Created a chunk of size 673, which is longer than the specified 500\n",
      "Created a chunk of size 546, which is longer than the specified 500\n",
      "Created a chunk of size 571, which is longer than the specified 500\n",
      "Created a chunk of size 579, which is longer than the specified 500\n",
      "Created a chunk of size 564, which is longer than the specified 500\n",
      "Created a chunk of size 544, which is longer than the specified 500\n",
      "Created a chunk of size 784, which is longer than the specified 500\n",
      "Created a chunk of size 577, which is longer than the specified 500\n",
      "Created a chunk of size 875, which is longer than the specified 500\n",
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 683, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 622, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 566, which is longer than the specified 500\n",
      "Created a chunk of size 579, which is longer than the specified 500\n",
      "Created a chunk of size 569, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n",
      "Created a chunk of size 551, which is longer than the specified 500\n",
      "Created a chunk of size 1052, which is longer than the specified 500\n",
      "Created a chunk of size 617, which is longer than the specified 500\n",
      "Created a chunk of size 808, which is longer than the specified 500\n",
      "Created a chunk of size 553, which is longer than the specified 500\n",
      "Created a chunk of size 662, which is longer than the specified 500\n",
      "Created a chunk of size 823, which is longer than the specified 500\n",
      "Created a chunk of size 734, which is longer than the specified 500\n",
      "Created a chunk of size 576, which is longer than the specified 500\n",
      "Created a chunk of size 627, which is longer than the specified 500\n",
      "Created a chunk of size 555, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 580, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 700, which is longer than the specified 500\n",
      "Created a chunk of size 647, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 579, which is longer than the specified 500\n",
      "Created a chunk of size 703, which is longer than the specified 500\n",
      "Created a chunk of size 566, which is longer than the specified 500\n",
      "Created a chunk of size 636, which is longer than the specified 500\n",
      "Created a chunk of size 598, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n",
      "Created a chunk of size 560, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 719, which is longer than the specified 500\n",
      "Created a chunk of size 712, which is longer than the specified 500\n",
      "Created a chunk of size 540, which is longer than the specified 500\n",
      "Created a chunk of size 589, which is longer than the specified 500\n",
      "Created a chunk of size 649, which is longer than the specified 500\n",
      "Created a chunk of size 553, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaned /home/laisky/data/langchain/pdf/security/CSAPP-Computer.Systems.A.Programmers.Perspective.3rd.Global.Edition.2015.pdf\n",
      "scaned /home/laisky/data/langchain/pdf/security/TEE/SGX/Remote Attestation for Multi-Package Platforms using Intel®SGX Datacenter Attestation Primitives (DCAP).pdf\n",
      "scaned /home/laisky/data/langchain/pdf/security/TEE/SGX/Supporting Third Party Attestation for Intel® SGX with Intel® Data Center Attestation Primitives.pdf\n",
      "scaned /home/laisky/data/langchain/pdf/security/TEE/SGX/Moat- Verifying Confidentiality of Enclave Programs.pdf\n"
     ]
    }
   ],
   "source": [
    "# incremental scan pdfs\n",
    "\n",
    "def gen_pdfs():\n",
    "    yield from glob.glob(\"/home/laisky/data/langchain/pdf/security/**/*.pdf\", recursive=True)\n",
    "\n",
    "def run_scan_pdfs():\n",
    "#     index = new_store()\n",
    "    total = 0\n",
    "    while True:\n",
    "        index = load_store(\n",
    "            dirpath=\"/home/laisky/data/langchain/index\",\n",
    "            name=\"security\",\n",
    "        )\n",
    "        n = embedding_pdfs(\n",
    "            index=index,\n",
    "            fpaths=gen_pdfs(),\n",
    "            url=\"https://s3.laisky.com/public/papers/security/\",\n",
    "            replace_by_url=\"/home/laisky/data/langchain/pdf/security/\",\n",
    "        )\n",
    "        total += n\n",
    "        save_store(\n",
    "            index=index, \n",
    "            dirpath=\"/home/laisky/data/langchain/index\", \n",
    "            name=\"security\",\n",
    "        )\n",
    "        \n",
    "        print(f\"scanned {total} files\")\n",
    "        if n == 0:\n",
    "            return\n",
    "        \n",
    "run_scan_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49778be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# incremental scan markdowns\n",
    "\n",
    "def gen_markdowns():\n",
    "    yield \"/home/laisky/data/langchain/basebit/doc/content/terms.md\"\n",
    "    yield from glob.glob(\"/home/laisky/data/langchain/basebit/doc/content/research/**/*.md\", recursive=True)\n",
    "    \n",
    "\n",
    "def run_scan_markdowns():\n",
    "#         index = new_store()\n",
    "    while True:\n",
    "        index = load_store(\n",
    "            dirpath=\"/home/laisky/data/langchain/index\",\n",
    "            name=\"security\",\n",
    "        )\n",
    "        files = gen_markdowns()\n",
    "        n = embedding_markdowns(\n",
    "            index=index,\n",
    "            fpaths=files,\n",
    "            url=\"https://s3.laisky.com/public/papers/security/\",\n",
    "            replace_by_url=\"/home/laisky/data/langchain/pdf/security/\",\n",
    "        )\n",
    "        save_store(\n",
    "            index=index,\n",
    "            dirpath=\"/home/laisky/data/langchain/index/\", \n",
    "            name=\"security\",\n",
    "        )\n",
    "        \n",
    "        print(f\"{n=}\")\n",
    "        if n == 0:\n",
    "            return\n",
    "        \n",
    "        \n",
    "run_scan_markdowns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9c77ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 生成用于问答的 query chain\n",
    "# ====================================\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "index = load_store(\n",
    "    dirpath=\"/home/laisky/data/langchain/index\",\n",
    "    name=\"security\",\n",
    ")\n",
    "chain = VectorDBQAWithSourcesChain.from_llm(\n",
    "    llm=OpenAI(\n",
    "        temperature=0, \n",
    "        max_tokens=1000,\n",
    "        model_name=\"text-davinci-003\",\n",
    "        streaming=False,\n",
    "    ), \n",
    "#     retriever=VectorStoreRetriever(vectorstore=index.store, search_kwargs={\"filter\":{\"type\":\"filter\"},\"k\":3},),\n",
    "    vectorstore=index.store,\n",
    "    reduce_k_below_max_tokens=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec62c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤔️: 安全的哈希函数应该具备哪些性质\n",
      "\n",
      "🤖️: A secure hash function should have the properties of pre-\n",
      "    image resistance, second pre-image resistance, and\n",
      "    collision resistance, as well as high security to\n",
      "    prevent attacks, a non-negative constant for the system\n",
      "    to learn after the algorithm has determined the system\n",
      "    synchronization, and a neural network synchronization\n",
      "    determination algorithm based on the output of the\n",
      "    hidden unit.\n",
      "\n",
      "📖: https://en.wikipedia.org/wiki/Cryptographic_hash_function#Security_requirements, https://s3.laisky.com/public/papers/security/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%90%8C%E6%AD%A5%E7%9A%84%E5%88%A4%E5%AE%9A%E5%8F%8A%E5%9C%A8%E7%A5%9E%E7%BB%8F%E5%AF%86%E7%A0%81%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.pdf#page=3\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# ask pdf embeddings\n",
    "# ====================================\n",
    "question = \"安全的哈希函数应该具备哪些性质\"\n",
    "result = chain(\n",
    "    {\n",
    "        \"question\": question,\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")\n",
    "\n",
    "print(f\"🤔️: {question}\\n\")\n",
    "print(f\"🤖️: {pretty_print(result['answer'])}\\n\")\n",
    "print(f\"📖: {result['sources']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
