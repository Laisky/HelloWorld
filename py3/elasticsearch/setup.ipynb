{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '1d449827cfa6',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'X3dZ4RPMTa-2av-DftNkfQ',\n",
       " 'version': {'number': '7.8.1',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': 'b5ca9c58fb664ca8bf9e4057fc229b3396bf3a89',\n",
       "  'build_date': '2020-07-21T16:40:44.668009Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.5.1',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connection\n",
    "import datetime\n",
    "from random import random, randint\n",
    "\n",
    "import requests\n",
    "import yaml\n",
    "from elasticsearch.helpers import bulk, parallel_bulk\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "config = yaml.load(open(\"/opt/configs/360/yunjia.yml\", 'rb').read(), Loader=yaml.CLoader)\n",
    "\n",
    "# api = 'http://xxx:8200/'  #general v2\n",
    "# api = 'http://xxx:8200/'  # general v3\n",
    "\n",
    "api = config['elasticsearch']['bushu-1']['api']\n",
    "es = Elasticsearch([api])\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current cluster settings\n",
    "\n",
    "requests.get(api + '_cluster/settings?include_defaults=true').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster settings\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/6.8/disk-allocator.html\n",
    "\n",
    "url = api + '_cluster/settings'\n",
    "data = {\n",
    "    \"transient\": {\n",
    "#         \"cluster.routing.allocation.cluster_concurrent_rebalance\": 4,  # default 2\n",
    "#         \"cluster.routing.allocation.node_concurrent_recoveries\": 4,  # default 2\n",
    "#         \"indices.recovery.max_bytes_per_sec\": \"200mb\",  # default 40mb\n",
    "        \"cluster.routing.allocation.disk.threshold_enabled\": True,  # default true\n",
    "        \"cluster.routing.allocation.disk.watermark.low\": \"90%\",  # default 85%, stop new replica shards\n",
    "        \"cluster.routing.allocation.disk.watermark.high\": \"98%\",  # default 90%, stop all new shards\n",
    "        \"cluster.routing.allocation.disk.watermark.flood_stage\": \"99%\",  # default 95%, readonly\n",
    "#         \"cluster.routing.allocation.enable\": \"primary\"\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(url, json=data)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "url = api+\"perf-spring-logs-write/logs/_bulk\"\n",
    "d = {\"@timestamp\": \"2018-12-07T05:00:00.000+08:00\", \"app\": \"test\", \"message\": \"tt2\"}\n",
    "header = {\"Content-encoding\": \"gzip\"}\n",
    "\n",
    "cnt = \"\"\n",
    "for _ in range(700):\n",
    "    cnt += json.dumps({\"index\": {}}) + '\\n'\n",
    "    cnt += json.dumps(d) + \"\\n\"\n",
    "    \n",
    "r = requests.post(url, headers=header, data=gzip.compress(cnt.encode('utf8')))\n",
    "print(r.status_code)\n",
    "# r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "url = api+\"test/doc\"\n",
    "\n",
    "data = {\n",
    "    \"text2\": 123,\n",
    "}\n",
    "\n",
    "r = requests.post(url, ,json=data)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uri = '_cluster/health'\n",
    "uri = '_cluster/pending_tasks'\n",
    "uri = '_cat/nodes?v'\n",
    "# uri = '_node/stats/jvm?pretty'\n",
    "# uri = '_node/stats/process?pretty'\n",
    "# uri = '_node/hot_threads?human=true'\n",
    "# uri = '_tasks'\n",
    "uri = '_stats'\n",
    "\n",
    "# requests.get(api+uri).json()\n",
    "requests.get(api+uri).json()['indices']['uat-spark-logs']['primaries']['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# indexes\n",
    "\n",
    "def delete_all_indexes():\n",
    "    for idx in es.indices.get_alias('*').keys():\n",
    "        if idx.startswith('.') \\\n",
    "                or idx in ('fluentd', 'test', 'simpleauth'):\n",
    "            continue\n",
    "            \n",
    "        if idx.startswith('zipkin_') or idx.startswith('zipkin-'):\n",
    "            print(f\"{idx} delete_index(idx)\")\n",
    "        \n",
    "            \n",
    "def show_all_indexes():\n",
    "    return list(es.indices.get_alias('*').keys())\n",
    "\n",
    "\n",
    "def delete_index(index):\n",
    "    return es.indices.delete(index=index)\n",
    "\n",
    "\n",
    "\n",
    "delete_all_indexes()\n",
    "# delete_index('sit-cp-logs')\n",
    "# delete_index('sit-spring-logs')\n",
    "# delete_index('uat-spring-logs')\n",
    "# delete_index('perf-spring-logs')\n",
    "# delete_index('prod-spring-logs')\n",
    "sorted(show_all_indexes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in show_all_indexes():\n",
    "    if idx.startswith('zipkin:'):\n",
    "        delete_index(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "reg = re.compile('.*-write')\n",
    "for idx in show_all_indexes():\n",
    "    if reg.match(idx):\n",
    "        print('delete', idx)\n",
    "        delete_index(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete documents\n",
    "body = {\n",
    "    'query': {\n",
    "        'match_all': {}\n",
    "    },\n",
    "    'size': '100000',\n",
    "}\n",
    "\n",
    "def delete_docus_in_index(index, type_):\n",
    "    r = requests.post(api+'{}/{}/_delete_by_query?pretty'.format(index, type_), json=body)\n",
    "    return r.json()\n",
    "    \n",
    "    \n",
    "delete_docus_in_index('sit-connector-logs', 'logs')\n",
    "# delete_docus_in_index('uat-spark-logs', 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "# no need for rollover\n",
    "\n",
    "def create_index(index):\n",
    "    data = {\n",
    "        'settings': {\n",
    "            'number_of_shards': 3,\n",
    "            'number_of_replicas': 1,\n",
    "            \"index.store.type\": \"niofs\",\n",
    "        }\n",
    "    }\n",
    "    r = requests.put(api+index, json=data, timeout=3)\n",
    "    print(r.json())\n",
    "\n",
    "# create_index('logs')\n",
    "    \n",
    "# index\n",
    "# create_index(index='sit-spring-logs-v3')\n",
    "# create_index(index='sit-spark-logs')\n",
    "# create_index(index='sit-cp-logs')\n",
    "# create_index(index='sit-geely-logs')\n",
    "# create_index(index='sit-gateway-logs')\n",
    "# create_index(index='sit-connector-logs')\n",
    "# create_index(index='sit-emqtt-logs')\n",
    "# create_index(index='sit-bigdata-logs')\n",
    "create_index(index='sit-speech-logs')\n",
    "\n",
    "# uat\n",
    "# create_index(index='uat-spring-logs-v2')\n",
    "# create_index(index='uat-spark-logs')\n",
    "# create_index(index='uat-cp-logs')\n",
    "# create_index(index='uat-gateway-logs')\n",
    "# create_index(index='uat-connector-logs')\n",
    "# create_index(index='uat-emqtt-logs')\n",
    "\n",
    "\n",
    "# perf\n",
    "# create_index(index='perf-spring-logs-v2')\n",
    "# create_index(index='perf-spark-logs')\n",
    "# create_index(index='perf-cp-logs')\n",
    "# create_index(index='perf-geely-logs')\n",
    "# create_index(index='perf-gateway-logs')\n",
    "# create_index(index='perf-connector-logs')\n",
    "# create_index(index='perf-emqtt-logs')\n",
    "\n",
    "\n",
    "# prod\n",
    "# create_index(index='prod-spring-logs-v2')\n",
    "# create_index(index='prod-spark-logs')\n",
    "# create_index(index='prod-cp-logs')\n",
    "# create_index(index='prod-gateway-logs')\n",
    "# create_index(index='prod-connector-logs')\n",
    "# create_index(index='prod-geely-logs')\n",
    "# create_index(index='prod-emqtt-logs')\n",
    "# create_index(index='prod-bigdata-logs')\n",
    "create_index(index='prod-speech-logs')\n",
    "\n",
    "# test\n",
    "# create_index(index='test')\n",
    "# create_index(index='es-stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put spark mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "#             \"time\": {\n",
    "#                 \"type\": \"date\",\n",
    "#                 \"format\": \"yyyy-MM-dd HH:mm:ss Z\"\n",
    "#             },\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"app_info\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "# print(create_mapping('perf-spark-logs', 'logs'))\n",
    "# print(create_mapping('uat-spark-logs', 'logs'))\n",
    "print(create_mapping('sit-bigdata_wuling-logs', 'logs'))\n",
    "# print(create_mapping('prod-spark-logs', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put bigdata mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "#         \"properties\": {\n",
    "#             \"happentime\": {\n",
    "#                 \"type\": \"date\",\n",
    "#                 \"format\": \"yyyy-MM-ddTHH:mm:ss\"\n",
    "#             },\n",
    "#             \"level\": {\n",
    "#                 \"type\": \"keyword\",\n",
    "#                 \"index\": \"not_analyzed\",\n",
    "#                 \"doc_values\": True,\n",
    "#             },\n",
    "#             \"app_info\": {\n",
    "#                 \"type\": \"keyword\",\n",
    "#                 \"index\": \"not_analyzed\",\n",
    "#                 \"doc_values\": True,\n",
    "#             },\n",
    "#             \"message\": {\n",
    "#                 \"type\": \"string\",\n",
    "#             },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "print(create_mapping('sit-bigdata-logs', 'logs'))\n",
    "print(create_mapping('prod-bigdata-logs', 'logs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put spring mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"app\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"class\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"thread\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"type\": \"short\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"datasource\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "# print(create_mapping('perf-spring-logs-v2', 'logs'))\n",
    "# print(create_mapping('uat-spring-logs-v2', 'logs'))\n",
    "print(create_mapping('sit-spring-logs-v3', 'logs'))\n",
    "# print(create_mapping('prod-spring-logs-v2', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put gateway mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"app\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"class\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"thread\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"type\": \"short\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "print(create_mapping('perf-gateway-logs', 'logs'))\n",
    "print(create_mapping('uat-gateway-logs', 'logs'))\n",
    "print(create_mapping('sit-gateway-logs', 'logs'))\n",
    "print(create_mapping('prod-gateway-logs', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put connector mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"app\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"class\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"thread\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"type\": \"short\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "print(create_mapping('perf-connector-logs', 'logs'))\n",
    "print(create_mapping('uat-connector-logs', 'logs'))\n",
    "print(create_mapping('sit-connector-logs', 'logs'))\n",
    "print(create_mapping('prod-connector-logs', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put geely mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "#             \"time\": {\n",
    "#                 \"type\": \"date\",\n",
    "#                 \"format\": \"yyyy-MM-dd HH:mm:ss.SSS Z\"\n",
    "#             },\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"class\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"thread\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"project\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"type\": \"integer\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "print(create_mapping('test', 'logs'))\n",
    "print(create_mapping('sit-geely-logs', 'logs'))\n",
    "print(create_mapping('perf-geely-logs', 'logs'))\n",
    "print(create_mapping('prod-geely-logs-v2', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "            \"level\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },\n",
    "            \"class\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            },            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"datasource\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"index\": \"not_analyzed\",\n",
    "                \"doc_values\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(index, r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "print(create_mapping('sit-cp-logs', 'logs'))\n",
    "print(create_mapping('uat-cp-logs', 'logs'))\n",
    "print(create_mapping('perf-cp-logs', 'logs'))\n",
    "print(create_mapping('prod-cp-logs', 'logs'))\n",
    "# print(create_mapping('test', 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put test mapping\n",
    "\n",
    "def create_mapping(index, type_):\n",
    "    url = '{}{}/_mapping/{}'.format(api, index, type_)\n",
    "    data = {\n",
    "        \"properties\": {\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        },\n",
    "        \"_ttl\": {\n",
    "            \"enabled\": True,\n",
    "            \"default\": \"1s\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.put(url, json=data)\n",
    "    print(r.text)\n",
    "    return r.status_code\n",
    "\n",
    "\n",
    "\n",
    "print(create_mapping('test', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reindex\n",
    "url = api+'_reindex'\n",
    "\n",
    "def reindex(fr_idx, to_idx):\n",
    "    data = {\n",
    "    #     'size': 100000,\n",
    "        \"conflicts\": \"proceed\",\n",
    "        'source': {\n",
    "            'remote': {\n",
    "                'host': 'http://1.1.1.1:8200/',\n",
    "                'username': 'superuser',\n",
    "                'password': 'xxx',\n",
    "            },        \n",
    "            'index': fr_idx,\n",
    "            'type': 'stats',\n",
    "        },\n",
    "        'dest': {\n",
    "            'index': to_idx,\n",
    "    #         \"op_type\": \"create\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = ''\n",
    "    try:\n",
    "        r = requests.post(url, json=data, timeout=3)\n",
    "        r = r.json()\n",
    "    except requests.Timeout:\n",
    "        pass\n",
    "    \n",
    "    print(fr_idx, r)\n",
    "    \n",
    "    \n",
    "# reindex\n",
    "reindex('monitor-stats-alias', 'monitor-stats-write')\n",
    "# reindex('uat-spark-logs-write', 'uat-spark-logs-2018.05.29-1')\n",
    "# reindex('perf-spark-logs-write', 'perf-spark-logs-2018.05.29-1')\n",
    "# reindex('prod-spark-logs-write', 'prod-spark-logs-2018.05.29-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex batch\n",
    "\n",
    "import re\n",
    "\n",
    "source_api = 'http://xxx:8999/1037308040/'\n",
    "dest_api = 'http://xxx:8200/'\n",
    "\n",
    "idx_reg = re.compile('\\w+-\\w+-\\w+-.*')\n",
    "\n",
    "\n",
    "def reindex_batch(idx):\n",
    "    url = api+'_reindex'\n",
    "    data = {\n",
    "        'conflicts': 'proceed',\n",
    "        'source': {\n",
    "            'remote': {\n",
    "                'host': source_api,\n",
    "            },\n",
    "            'index': idx,\n",
    "            'type': 'logs',\n",
    "        },\n",
    "        'dest': {\n",
    "            'index': idx\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        print('reindex for {}'.format(idx))\n",
    "        r = requests.post(url, json=data, timeout=3)\n",
    "    except requests.Timeout:\n",
    "        pass\n",
    "    \n",
    "    print(\"all done\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_all_indices():\n",
    "    url = source_api+\"_cat/indices/?h=index&format=json\"\n",
    "    r = requests.get(url).json()\n",
    "    return filter(lambda v: idx_reg.match(v), map(lambda d: d['index'], r))\n",
    "        \n",
    "        \n",
    "for idx in get_all_indices():\n",
    "#     print(idx)\n",
    "    reindex_batch(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alias\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-aliases.html\n",
    "\n",
    "\n",
    "url = api+\"_aliases\"\n",
    "print(url)\n",
    "\n",
    "def create_alias(index, alias, f=None):\n",
    "    data = {\n",
    "        'actions': [\n",
    "            {\"add\": {\n",
    "                \"index\": index, \n",
    "                \"alias\": alias,\n",
    "            }}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if f:\n",
    "        data['actions'][0]['add']['filter'] = f\n",
    "\n",
    "    r = requests.post(url, json=data)\n",
    "    print(index, r.status_code,r.json())\n",
    "    \n",
    "    \n",
    "# alias\n",
    "# create_alias('sit-spark-logs-2018.05.29-1', 'sit-spark-logs-write')\n",
    "# create_alias('uat-spark-logs-2018.05.29-1', 'uat-spark-logs-write')\n",
    "# create_alias('perf-spark-logs-2018.05.29-1', 'perf-spark-logs-write')\n",
    "# create_alias('prod-spark-logs-2018.05.29-1', 'prod-spark-logs-write')\n",
    "create_alias('zipkin_prod:span*', 'zipkin-prod-alias')\n",
    "\n",
    "# write-alias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, # auth\n",
    "\n",
    "indexes = [\n",
    "    '/.kibana',\n",
    "    '/es-stats',\n",
    "    '/perf-cp-logs',\n",
    "    '/perf-spark-logs',\n",
    "    '/perf-spring',\n",
    "    '/perf-spring-logs',\n",
    "    '/prod-cp-logs',\n",
    "    '/prod-spark-logs',\n",
    "    '/prod-spring-logs',\n",
    "    '/simpleauth',\n",
    "    '/sit-cp-logs',\n",
    "    '/sit-spark-logs',\n",
    "    '/sit-spring-logs',\n",
    "    '/uat-cp-logs',\n",
    "    '/uat-spark-logs',\n",
    "    '/uat-spring-logs',\n",
    "]\n",
    "\n",
    "indexes = [\"sit-speech-logs-alias\", \"prod-speech-logs-alias\"]\n",
    "\n",
    "url = '{}_user/create'.format(api)\n",
    "# url = api + '_user/delete'\n",
    "# url = '{}_user/alter'.format(api)\n",
    "data = {\n",
    "    'username': 'speech',\n",
    "    'password': 'xxx',\n",
    "#     'ip_whitelist': ['172.16.4.*'],\n",
    "    'ip_whitelist': ['*'],\n",
    "    'get_path': ['/'], #+indexes,\n",
    "    'head_path': ['/'], #+indexes,\n",
    "    'post_path': ['/'], #+indexes,\n",
    "    \"put_path\": [\"/\"],\n",
    "    'del_path': ['/'],\n",
    "    'hostname_whitelist': ['*'],\n",
    "#     'read_index': [\"*\"],\n",
    "#     'write_index': [\"*\"],\n",
    "    'read_index': [\"sit-speech-logs-alias\", \"prod-speech-logs-alias\", \".kibana\"],\n",
    "    'write_index': [\".kibana\"],\n",
    "}\n",
    "\n",
    "r = requests.post(url, json=data)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipkin users\n",
    "\n",
    "\n",
    "url = \"{}_user/create\".format(api)\n",
    "# url = api + '_user/delete'\n",
    "# url = '{}_user/alter'.format(api)\n",
    "data = {\n",
    "    \"username\": \"123\",\n",
    "    \"password\": \"123\",\n",
    "    \"ip_whitelist\": [\"*\"],\n",
    "    \"get_path\": [\"/\", \"/_\", \"/zipkin_prod:\"],\n",
    "    \"head_path\": [\"/\", \"/_\", \"/zipkin_prod:\"],\n",
    "    \"put_path\": [\"/_\", \"/zipkin_prod:\"],\n",
    "    \"post_path\": [\"/zipkin_prod:\", \"/_\"],\n",
    "    \"hostname_whitelist\": [\"*\"],\n",
    "    \"read_index\": [\"*\"],\n",
    "    \"write_index\": [\"*\"],\n",
    "}\n",
    "\n",
    "r = requests.post(url, json=data)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show user\n",
    "url = '{}_user/show'.format(api)\n",
    "requests.post(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk insert doucuments\n",
    "\n",
    "\n",
    "def generate_level():\n",
    "    if random() < 0.8:\n",
    "        return 'INFO'\n",
    "    else:\n",
    "        return 'ERROR'\n",
    "    \n",
    "    \n",
    "def generate_time():\n",
    "    ts = (datetime.datetime.now() - datetime.timedelta(hours=randint(10, 100))).isoformat(timespec='milliseconds')\n",
    "    return '{}Z'.format(ts)\n",
    "    \n",
    "    \n",
    "\n",
    "def generate_data(index, type_, n):\n",
    "    for _ in range(n):\n",
    "        l = generate_level()\n",
    "        t = generate_time()\n",
    "#         print(t)\n",
    "        yield {\n",
    "            '_index': index,\n",
    "            '_type': type_,\n",
    "            '_source': {\n",
    "                'level': l,\n",
    "                'message': '{} {} xxx'.format(t, l),\n",
    "                '@timestamp': t,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "def insert_docus(index, type_, n):\n",
    "    for resp in parallel_bulk(es, generate_data(index, type_, n), thread_count=10):\n",
    "        continue\n",
    "\n",
    "    print('resp', resp)\n",
    "\n",
    "\n",
    "index = 'sit-spark-logs'\n",
    "type_ = 'logs'\n",
    "insert_docus(index, type_, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rollover\n",
    "# create index\n",
    "\n",
    "\n",
    "def create_index_rollover(index):\n",
    "    \"\"\"create index rollover\n",
    "\n",
    "    like `sit-geely-logs-2016.10.31-000001`\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"aliases\": {index + \"-write\": {}, index + \"-alias\": {}},\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"number_of_shards\": 7,\n",
    "                \"number_of_replicas\": 1,\n",
    "                \"store.type\": \"niofs\",\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"logs\": {\n",
    "                \"_source\": {\"enabled\": True},\n",
    "                \"_all\": {\"enabled\": False},\n",
    "                # \"properties\": {\n",
    "                #     \"msgid\": {\"type\": \"long\"},\n",
    "                #     \"tag\": {\n",
    "                #         \"type\": \"keyword\",\n",
    "                #         \"doc_values\": True,\n",
    "                #     },\n",
    "                #     \"vin\": {\"type\": \"keyword\"},\n",
    "                #     \"rowkey\": {\"type\": \"keyword\"},\n",
    "                #     \"location\": {\"type\": \"geo_point\"},\n",
    "                # },\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    print(\"api\", api + \"%3C{}-%7Bnow%2Fd%7D-1%3E\".format(index))\n",
    "    r = requests.put(api + \"%3C{}-%7Bnow%2Fd%7D-1%3E\".format(index), json=data)\n",
    "    #     r = requests.put(api+'{}-2018.05.25-1'.format(index), json=data)\n",
    "    try:\n",
    "        print(index, r.json())\n",
    "    except Exception:\n",
    "        print(r.text)\n",
    "\n",
    "\n",
    "# create\n",
    "# create_index_rollover(index=\"sit-speech-logs\")\n",
    "# create_index_rollover(index=\"perf-speech-logs\")\n",
    "# create_index_rollover(index=\"uat-speech-logs\")\n",
    "# create_index_rollover(index=\"prod-speech-logs\")\n",
    "\n",
    "\n",
    "def rollover_index(index):\n",
    "    data = {\n",
    "        'conditions': {\n",
    "            'max_age': '1s',\n",
    "        },\n",
    "        \"aliases\": {\n",
    "            \"{}-alias\".format(index): {},\n",
    "        },\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"number_of_shards\": 2,\n",
    "                \"number_of_replicas\": 1,\n",
    "                \"store.type\": \"niofs\",\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"logs\": {\n",
    "                \"_source\": {\n",
    "                    \"enabled\": True,\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"level\": {\n",
    "                        \"type\": \"keyword\",\n",
    "                        \"index\": \"not_analyzed\",\n",
    "                        \"doc_values\": True,\n",
    "                    },\n",
    "                    \"class\": {\n",
    "                        \"type\": \"keyword\",\n",
    "                        \"index\": \"not_analyzed\",\n",
    "                        \"doc_values\": True,\n",
    "                    },            \"message\": {\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    \"datasource\": {\n",
    "                        \"type\": \"keyword\",\n",
    "                        \"index\": \"not_analyzed\",\n",
    "                        \"doc_values\": True,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    print('>> rollover: {}{}-write/_rollover'.format(api, index))\n",
    "    r = requests.post('{}{}-write/_rollover'.format(api, index), json=data)\n",
    "    print(index, r.json())\n",
    "\n",
    "\n",
    "# rollover_index(index='sit-cp-logs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reroute\n",
    "url = api + \"_cluster/reroute?retry_failed=true\"\n",
    "\n",
    "requests.post(url).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
