{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "import re\n",
    "import sys\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor,wait\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import tweepy\n",
    "from tweepy import API, OAuthHandler\n",
    "from kipp.decorator import debug_wrapper\n",
    "\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=10)\n",
    "\n",
    "\n",
    "# sys.path.append(r'/Users/laisky/repo/laisky/ramjet/ramjet/settings')\n",
    "sys.path.append(r'/opt/configs/ramjet')\n",
    "sys.path\n",
    "import prd\n",
    "\n",
    "mongo = MongoClient(\n",
    "    f\"mongodb://{prd.MONGO_USER}:{prd.MONGO_PASSWD}@{prd.MONGO_HOST}:{prd.MONGO_PORT}/{prd.MONGO_DB}\",\n",
    ")\n",
    "tweets = mongo['twitter']['tweets']\n",
    "\n",
    "auth = OAuthHandler(prd.CONSUMER_KEY, prd.CONSUMER_SECRET)\n",
    "auth.set_access_token(prd.ACCESS_TOKEN, prd.ACCESS_TOKEN_SECRET)\n",
    "api = API(auth, wait_on_rate_limit=True, parser=tweepy.parsers.JSONParser())\n",
    "api.me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "api.get_status(538588763056656385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "\n",
    "tweets.create_index([('created_at', pymongo.DESCENDING)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete tweets\n",
    "\n",
    "# @debug_wrapper\n",
    "def is_status_tobe_delete(tweet):\n",
    "    if len(tweet.get('entities', {}).get(\"hashtags\", [])) >= 1:\n",
    "        return False\n",
    "    \n",
    "    if tweet['created_at'] > datetime(2021, 1, 1):\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    if tweets.count_documents({\"in_reply_to_status_id\": tweet['id']}) > 0:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    return True\n",
    "    \n",
    "    \n",
    "\n",
    "@debug_wrapper\n",
    "def run_delete():\n",
    "        delete_q = Queue(maxsize=50)\n",
    "        fs = []\n",
    "        fs.append(executor.submit(gen_tweet, delete_q))\n",
    "        for _ in range(10):\n",
    "            fs.append(executor.submit(delete_tweet, delete_q))\n",
    "            \n",
    "        wait(fs)\n",
    "            \n",
    "    \n",
    "\n",
    "@debug_wrapper\n",
    "def gen_tweet(q: Queue):\n",
    "    for tweet in tweets.find({'deleted': {'$ne': True}}).sort('created_at', 1):\n",
    "        q.put(tweet)\n",
    "\n",
    "@debug_wrapper\n",
    "def delete_tweet(q: Queue):\n",
    "    while 1:\n",
    "        tweet = q.get()\n",
    "        if not is_status_tobe_delete(tweet):\n",
    "            print(f\"pass tweet {tweet['id']} {tweet['created_at']}\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            api.destroy_status(tweet['id'])\n",
    "        except tweepy.error.TweepError as err:\n",
    "            if 'No status found with that ID.' in f'{err}':\n",
    "                # deleted\n",
    "                tweets.update_one(\n",
    "                    {'_id': tweet['_id']},\n",
    "                    {'$set': {\"deleted\": True}},\n",
    "                )\n",
    "                print(f\"mark {tweet['id']} {tweet['created_at']} deleted\")\n",
    "                continue\n",
    "\n",
    "            traceback.print_exc()\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "        tweets.update_one(\n",
    "            {'_id': tweet['_id']},\n",
    "            {'$set': {\"deleted\": True}},\n",
    "        )\n",
    "\n",
    "#         n_del += 1\n",
    "        print(\"delete\", tweet['id'],tweet['created_at'])\n",
    "#         if n % 1000 == 0:\n",
    "#             print(f\">> scan {n} statuses\")\n",
    "#         if n_del % 100 == 0:\n",
    "#             print(f\">> delete {n_del} statuses\")\n",
    "\n",
    "\n",
    "run_delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download image\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "dirpath = r'/var/www/uploads/twitter'\n",
    "# dirpath = r'/Users/laisky/Downloads'\n",
    "\n",
    "\n",
    "def download_images_for_tweet(tweet):\n",
    "    for img in tweet['entities']['media']:\n",
    "        with requests.get(img['media_url_https']+\":orig\") as r:\n",
    "            if r.status_code != 200:\n",
    "                print(f\"download error: [{r.status_code}]{r.content}\")\n",
    "                continue\n",
    "                \n",
    "            fpath = Path(dirpath, img['media_url_https'].split(\"/\")[-1])\n",
    "            if fpath.is_file():\n",
    "                continue\n",
    "                \n",
    "            with open(fpath, 'wb') as f:\n",
    "                f.write(r.content) \n",
    "                \n",
    "            print(\"tweet img ok\", tweet['id'], fpath)\n",
    "            \n",
    "\n",
    "def download_images():\n",
    "    for tweet in tweets.find({\"entities.media\": {\"$exists\": 1}}, no_cursor_timeout=True).sort(\"_id\", -1):\n",
    "        download_images_for_tweet(tweet)\n",
    "        \n",
    "        \n",
    "download_images()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download related tweets\n",
    "\n",
    "def twitter_api_parser(tweet):\n",
    "    reg_topic = re.compile(r\"[\\b|\\s]#(\\S+)\")\n",
    "    tweet['topics'] = reg_topic.findall(\n",
    "        tweet['text'].replace('.', '_')\n",
    "    )\n",
    "    tweet['created_at'] = datetime.strptime(\n",
    "        tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y'\n",
    "    )\n",
    "\n",
    "    # replace url\n",
    "    t = tweet['text']\n",
    "    if 't.co' in t:\n",
    "        # parse entities media\n",
    "        if 'media' in tweet['entities']:\n",
    "            for media in tweet['entities']['media']:\n",
    "                surl = media['url']\n",
    "                eurl = media['media_url']\n",
    "                t = t.replace(surl, eurl)\n",
    "\n",
    "        # parse entities urls\n",
    "        if 'urls' in tweet['entities']:\n",
    "            for d in tweet['entities']['urls']:\n",
    "                surl = d['url']\n",
    "                eurl = d['expanded_url']\n",
    "                t = t.replace(surl, eurl)\n",
    "\n",
    "        tweet['text'] = t\n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def save_relate_tweets(status):\n",
    "    related_ids = []\n",
    "    status.get(\"in_reply_to_status_id\") and related_ids.append(status['in_reply_to_status_id'])\n",
    "    status.get(\"retweeted_status\") and related_ids.append(status['retweeted_status']['id'])\n",
    "    status.get(\"quoted_status\") and related_ids.append(status['quoted_status']['id'])\n",
    "    related_ids = filter(lambda id_: not tweets.find_one({\"id\": id_}), related_ids)\n",
    "    \n",
    "    for id_ in related_ids:\n",
    "        try:\n",
    "            docu = api.get_status(id_)\n",
    "        except Exception as err:\n",
    "            print(f\"load tweet {id_} got error: {err}\")\n",
    "        else:\n",
    "            print(f\"save tweet [{docu['user']['screen_name']}]{docu['id']}\")\n",
    "            save_tweet(docu)\n",
    "            save_relate_tweets(docu)\n",
    "            \n",
    "def save_tweet(docu):\n",
    "    docu = twitter_api_parser(docu)\n",
    "    tweets.update_one(\n",
    "        {'id': docu['id']},\n",
    "        {'$set': docu},\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "def download_relate_tweets():\n",
    "    for tweet in tweets.find(no_cursor_timeout=True).sort(\"_id\", -1):\n",
    "        save_relate_tweets(tweet)\n",
    "\n",
    "        \n",
    "download_relate_tweets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
