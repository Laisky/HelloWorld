{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from datetime import datetime\n",
    "from queue import Queue\n",
    "\n",
    "import pymongo\n",
    "import tweepy\n",
    "from kipp.decorator import debug_wrapper\n",
    "from pymongo import MongoClient\n",
    "from tweepy import API, OAuthHandler\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=10)\n",
    "\n",
    "\n",
    "# sys.path.append(r'/Users/laisky/repo/laisky/ramjet/ramjet/settings')\n",
    "sys.path.append(r\"/opt/configs/ramjet\")\n",
    "sys.path\n",
    "import prd\n",
    "\n",
    "mongo = MongoClient(\n",
    "    f\"mongodb://{prd.MONGO_USER}:{prd.MONGO_PASSWD}@{prd.MONGO_HOST}:{prd.MONGO_PORT}/{prd.MONGO_DB}\",\n",
    ")\n",
    "tweets = mongo[\"twitter\"][\"tweets\"]\n",
    "\n",
    "auth = OAuthHandler(prd.CONSUMER_KEY, prd.CONSUMER_SECRET)\n",
    "auth.set_access_token(prd.ACCESS_TOKEN, prd.ACCESS_TOKEN_SECRET)\n",
    "api = API(auth, wait_on_rate_limit=True, parser=tweepy.parsers.JSONParser())\n",
    "api.me()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api.get_status(1350109300346281984, tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api.user_timeline(tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "\n",
    "# tweets.create_index([('created_at', pymongo.DESCENDING)])\n",
    "# tweets.create_index([('id', pymongo.DESCENDING)])\n",
    "tweets.create_index([('user.id', pymongo.DESCENDING)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete tweets\n",
    "\n",
    "# @debug_wrapper\n",
    "def is_status_tobe_delete(tweet):\n",
    "    if len(tweet.get(\"entities\", {}).get(\"hashtags\", [])) >= 1:\n",
    "        return False\n",
    "\n",
    "    if tweet[\"created_at\"] > datetime(2021, 1, 1):\n",
    "        return False\n",
    "\n",
    "    if tweet.get(\"in_reply_to_status_id\") is not None:\n",
    "        return False\n",
    "\n",
    "    if tweets.count_documents({\"in_reply_to_status_id\": tweet[\"id\"]}) > 0:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "@debug_wrapper\n",
    "def run_delete():\n",
    "    delete_q = Queue(maxsize=50)\n",
    "    fs = []\n",
    "    fs.append(executor.submit(gen_tweet, delete_q))\n",
    "    for _ in range(10):\n",
    "        fs.append(executor.submit(delete_tweet, delete_q))\n",
    "\n",
    "    wait(fs)\n",
    "\n",
    "\n",
    "@debug_wrapper\n",
    "def gen_tweet(q: Queue):\n",
    "    for tweet in tweets.find({\"deleted\": {\"$ne\": True}}).sort(\"created_at\", 1):\n",
    "        q.put(tweet)\n",
    "\n",
    "\n",
    "@debug_wrapper\n",
    "def delete_tweet(q: Queue):\n",
    "    while 1:\n",
    "        tweet = q.get()\n",
    "        if not is_status_tobe_delete(tweet):\n",
    "            print(f\"pass tweet {tweet['id']} {tweet['created_at']}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            api.destroy_status(tweet[\"id\"])\n",
    "        except tweepy.error.TweepError as err:\n",
    "            if \"No status found with that ID.\" in f\"{err}\":\n",
    "                # deleted\n",
    "                tweets.update_one(\n",
    "                    {\"_id\": tweet[\"_id\"]},\n",
    "                    {\"$set\": {\"deleted\": True}},\n",
    "                )\n",
    "                print(f\"mark {tweet['id']} {tweet['created_at']} deleted\")\n",
    "                continue\n",
    "\n",
    "            traceback.print_exc()\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "        tweets.update_one(\n",
    "            {\"_id\": tweet[\"_id\"]},\n",
    "            {\"$set\": {\"deleted\": True}},\n",
    "        )\n",
    "\n",
    "        #         n_del += 1\n",
    "        print(\"delete\", tweet[\"id\"], tweet[\"created_at\"])\n",
    "\n",
    "\n",
    "#         if n % 1000 == 0:\n",
    "#             print(f\">> scan {n} statuses\")\n",
    "#         if n_del % 100 == 0:\n",
    "#             print(f\">> delete {n_del} statuses\")\n",
    "\n",
    "\n",
    "run_delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download image\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "dirpath = r\"/var/www/uploads/twitter\"\n",
    "# dirpath = r'/Users/laisky/Downloads'\n",
    "\n",
    "\n",
    "def download_images_for_tweet(tweet):\n",
    "    for img in tweet[\"entities\"][\"media\"]:\n",
    "        with requests.get(img[\"media_url_https\"] + \":orig\") as r:\n",
    "            if r.status_code != 200:\n",
    "                print(f\"download error: [{r.status_code}]{r.content}\")\n",
    "                continue\n",
    "\n",
    "            fpath = Path(dirpath, img[\"media_url_https\"].split(\"/\")[-1])\n",
    "            if fpath.is_file():\n",
    "                continue\n",
    "\n",
    "            with open(fpath, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "            print(\"tweet img ok\", tweet[\"id\"], fpath)\n",
    "\n",
    "\n",
    "def download_images():\n",
    "    for tweet in tweets.find(\n",
    "        {\"entities.media\": {\"$exists\": 1}}, no_cursor_timeout=True\n",
    "    ).sort(\"_id\", -1):\n",
    "        download_images_for_tweet(tweet)\n",
    "\n",
    "\n",
    "download_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download related tweets\n",
    "\n",
    "\n",
    "def get_tweet_text(tweet: Dict[str, any]) -> str:\n",
    "    return tweet.get(\"full_text\") or tweet.get(\"text\")\n",
    "\n",
    "\n",
    "def twitter_api_parser(tweet: Dict[str, any]) -> Dict[str, any]:\n",
    "    \"\"\"Parse tweet document got from twitter api\"\"\"\n",
    "    reg_topic = re.compile(r\"[\\b|\\s]#(\\S+)\")\n",
    "    tweet[\"topics\"] = reg_topic.findall(get_tweet_text(tweet).replace(\".\", \"_\"))\n",
    "    tweet[\"created_at\"] = datetime.datetime.strptime(\n",
    "        tweet[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\"\n",
    "    )\n",
    "\n",
    "    # replace url\n",
    "    t = get_tweet_text(tweet)\n",
    "    if tweet.get(\"entities\"):\n",
    "        # parse entities media\n",
    "        entities = tweet.get(\"extended_entities\") or tweet.get(\"entities\")\n",
    "        if \"media\" in entities:\n",
    "            for media in tweet[\"entities\"][\"media\"]:\n",
    "                for surl in [\"url\", \"display_url\"]:\n",
    "                    durl = media.get(\"media_url_https\") or media[\"media_url\"]\n",
    "                    t = t.replace(surl, durl)\n",
    "\n",
    "        # parse entities urls\n",
    "        if \"urls\" in tweet[\"entities\"]:\n",
    "            for d in tweet[\"entities\"][\"urls\"]:\n",
    "                for surl in [\"url\", \"display_url\"]:\n",
    "                    eurl = d[\"expanded_url\"]\n",
    "                    t = t.replace(surl, eurl)\n",
    "\n",
    "        tweet[\"text\"] = t\n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def gen_related_tweets(\n",
    "    tweetCol: pymongo.collection.Collection, tweet: Dict[str, any]\n",
    ") -> Generator[str, None, None]:\n",
    "    related_ids = []\n",
    "    tweet.get(\"in_reply_to_status_id\") and related_ids.append(\n",
    "        tweet[\"in_reply_to_status_id\"]\n",
    "    )\n",
    "    tweet.get(\"retweeted_status\") and related_ids.append(\n",
    "        tweet[\"retweeted_status\"][\"id\"]\n",
    "    )\n",
    "    tweet.get(\"quoted_status\") and related_ids.append(tweet[\"quoted_status\"][\"id\"])\n",
    "    for _id in filter(lambda id_: not tweetCol.find_one({\"id\": id_}), related_ids):\n",
    "        yield _id\n",
    "\n",
    "\n",
    "def save_relate_tweets(status):\n",
    "    related_ids = []\n",
    "    status.get(\"in_reply_to_status_id\") and related_ids.append(\n",
    "        status[\"in_reply_to_status_id\"]\n",
    "    )\n",
    "    status.get(\"retweeted_status\") and related_ids.append(\n",
    "        status[\"retweeted_status\"][\"id\"]\n",
    "    )\n",
    "    status.get(\"quoted_status\") and related_ids.append(status[\"quoted_status\"][\"id\"])\n",
    "    related_ids = filter(lambda id_: not tweets.find_one({\"id\": id_}), related_ids)\n",
    "\n",
    "    for id_ in related_ids:\n",
    "        try:\n",
    "            docu = api.get_status(id_, tweet_mode=\"extended\")\n",
    "        except Exception as err:\n",
    "            print(f\"load tweet {id_} got error: {err}\")\n",
    "        else:\n",
    "            print(f\"save tweet [{docu['user']['screen_name']}]{docu['id']}\")\n",
    "            save_tweet(docu)\n",
    "            save_relate_tweets(docu)\n",
    "\n",
    "\n",
    "def save_tweet(docu):\n",
    "    docu = twitter_api_parser(docu)\n",
    "    tweets.update_one({\"id\": docu[\"id\"]}, {\"$set\": docu}, upsert=True)\n",
    "\n",
    "\n",
    "def download_relate_tweets():\n",
    "    for tweet in tweets.find(no_cursor_timeout=True).sort(\"_id\", -1):\n",
    "        save_relate_tweets(tweet)\n",
    "\n",
    "\n",
    "# download_relate_tweets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
